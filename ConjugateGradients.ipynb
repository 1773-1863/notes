{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjugate Gradients\n",
    "\n",
    "Solve Equations of form $b = Ax$ where $A$ is positive definite. If $A$ is invertible but not positive definite we apply the method to $A^\\top A x = A^\\top b$.\n",
    "\n",
    "\n",
    "Consider first \n",
    "\\begin{eqnarray*}\n",
    "F(x) & = & \\frac12 x^\\top A x\n",
    "\\end{eqnarray*}\n",
    "\n",
    "The method has the following form \n",
    "\n",
    "\\begin{eqnarray*}\n",
    "x(t+1) = x(t) + \\gamma(t) s(t)\n",
    "\\end{eqnarray*}\n",
    "$\\gamma(t)$ are scalar step size parameter and $s(t)$ are search directions for $t=0,1,\\dots$.\n",
    "Note that the gradient of $F$ is given as\n",
    "\\begin{eqnarray*}\n",
    "\\nabla F(x) \\mid_{x=x(t)} \\equiv g(t) = A x(t)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "It would be informative to contrast conjugate gradients to a gradient descent algorithm. A gradient descent algorithm would look like\n",
    "\\begin{eqnarray*}\n",
    "x(t+1) &=& x(t) - \\nu(t) g(t) \\\\ \n",
    "&=& x(t) - \\nu(t) A x(t) = (I - \\nu(t) A) x(t)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "In the conjugate gradient method, the search directions are chosen to be mutually conjugate meaning that\n",
    "\\begin{eqnarray*}\n",
    "s(t)^\\top A s(r) = 0 \\hspace{1cm} \\text{when} \\;\\; r \\neq t \n",
    "\\end{eqnarray*}\n",
    "Once $s(t)$ is chosen, $\\gamma(t)$ has a closed form solution. \n",
    "\n",
    "In the sequel, we will show how to select $s(t)$ and $\\gamma(t)$, but first provide an outline of the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustration of the algorithm\n",
    "At the first step, we select the search direction as the negative gradient\n",
    "\\begin{eqnarray*}\n",
    "s(0) & = &  -g(0) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "The search direction will be found\n",
    "\\begin{eqnarray*}\n",
    "\\gamma(0) & = & \\frac{s(0)^\\top g(0)}{s(0)^\\top A  s(0)} = -\\frac{g(0)^\\top g(0)}{g(0)^\\top A g(0)}\\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "and let \n",
    "\\begin{eqnarray*}\n",
    "x(1) & = & x(0) + \\frac{s(0)^\\top g(0)}{s(0)^\\top A  s(0)} s(0)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "At this stage, we can calculate the new gradient as \n",
    "\n",
    "\\begin{eqnarray*}\n",
    "g(1) & = & A x(1)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "To execute the next step, we need to select $s(1)$ as a conjugate direction\n",
    "\\begin{eqnarray*}\n",
    "s(0)^\\top A s(1) = 0\n",
    "\\end{eqnarray*}\n",
    "\n",
    "We would select the gradient $s(1) = -g(1)$, but this choice won't be necessarily a conjugate direction. A reasonable choice is choosing the new direction $s(1)$ such that we can represent the gradient as\n",
    "\\begin{eqnarray*}\n",
    "-g(1) =  s(1) - c_0(1) s(0)\n",
    "\\end{eqnarray*}\n",
    "where $c_0(1)$ denotes a scalar coefficient for the first search direction in computation of the gradient $g(1)$ at time $1$.\n",
    "\n",
    "This leads to \n",
    "\\begin{eqnarray*}\n",
    "s(0)^\\top A s(1) & = & - s(0)^\\top A g(1) + c_0(1) s(0)^\\top A s(0) = 0 \\\\\n",
    "c_0(1) & = &  \\frac{s(0)^\\top A g(1)}{s(0)^\\top A s(0)}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "s(1) & = & -g(1) + c_0(1) s(0)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "x(2) &= &x(1) + \\gamma(1) s(1) \\\\\n",
    "g(2) & = & A x(2) \\\\\n",
    "g(2) & = & A x(1) + \\gamma(1) A s(1) = g(1) + \\gamma(1) A s(1) \\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Similarly we want now\n",
    "\\begin{eqnarray*}\n",
    "-g(2) =  s(2) - c_1(2) s(1) - c_0(2) s(0)\n",
    "\\end{eqnarray*}\n",
    "where $c_1(2)$ and $c_0(2)$ denote scalar coefficients for the search direction $s(2)$ in computation of the gradient $g(2)$ at time $2$\n",
    "\n",
    "This leads to two equations\n",
    "\\begin{eqnarray*}\n",
    " s(2) & = & -g(2) + c_1(2)s(1) + c_0(2) s(0) \\\\\n",
    " s(0)^\\top A s(2) & = & -s(0)^\\top A g(2) + c_1(2) s(0)^\\top A s(1) + c_0(2) s(0)^\\top A s(0) \\\\\n",
    " s(1)^\\top A s(2) & = & -s(1)^\\top A g(2) + c_1(2) s(1)^\\top A s(1) + c_0(2) s(1)^\\top A s(0) \\\\\n",
    "\\end{eqnarray*}\n",
    "By conjugacy of $s(0), s(1)$ and $s(2)$ we have\n",
    "\\begin{eqnarray*}\n",
    " 0 & = & -s(0)^\\top A g(2) + c_0(2) s(0)^\\top A s(0) \\\\\n",
    " 0 & = & -s(1)^\\top A g(2) + c_1(2) s(1)^\\top A s(1) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "\\begin{eqnarray*}\n",
    " c_0(2) & = & \\frac{s(0)^\\top A g(2)}{s(0)^\\top A s(0)} = \\frac{s(0)^\\top A g(2)}{s(0)^\\top A s(0)}\\\\\n",
    " c_1(2) & = & \\frac{s(1)^\\top A g(2)}{s(1)^\\top A s(1)} \n",
    "\\end{eqnarray*}\n",
    "In the general case, we will need to find scalar coefficients $c_i(t)$ for the $i$'th search direction in computation of the gradient $g(t)$ at time $t$ $i = 0\\dots t-1$. In general we will have \n",
    "\\begin{eqnarray*}\n",
    "-g(t) & = &   s(t) - c_{t-1}(t) s(t-1) - c_{t-2}(t) s(t-2) - \\dots - c_{0}(t) s(0) \\\\ \n",
    "& = & s(t) - \\sum_{i=0}^{t-1} c_{i}(t) s(i)\n",
    "\\end{eqnarray*}\n",
    "In other words, we require that the gradient lives in the subspace spanned by $S_t = \\{ s(0), \\dots, s(t)$\\}, a set of mutually conjugate vectors where $s(i)^\\top A s(t) = $ for $i\\neq t$\n",
    "We will later show that most $c_i(t)$ are in fact $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the line search minimizer $\\gamma(t)$\n",
    "\n",
    "For given $x(t)$, $s(t)$ and $A$, we define $\\gamma(t)$ as the line search minimizer\n",
    "\\begin{eqnarray*}\n",
    "\\gamma(t) & = & \\arg\\min_{\\gamma}  F(x(t) + \\gamma s(t) )\n",
    "\\end{eqnarray*}\n",
    "\n",
    "This problem has the following solution\n",
    "\\begin{eqnarray*}\n",
    "U(\\gamma) & = & F(x(t) + \\gamma s(t) ) \\\\\n",
    "& = & \\frac12 (x(t) + \\gamma s(t))^\\top A (x(t) + \\gamma s(t)) \\\\\n",
    "& = & \\frac12 (x(t)^\\top + \\gamma s(t)^\\top ) (A x(t) + \\gamma A  s(t)) \\\\\n",
    "& = & \\frac12  x(t)^\\top A x(t) + \\gamma s(t)^\\top A x(t) + \\gamma^2 \\frac12 s(t)^\\top A  s(t) \\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\frac{d U}{d \\gamma} = s(t)^\\top A x(t) + \\gamma s(t)^\\top A  s(t) = 0 \\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\gamma(t) & = & - s(t)^\\top A x(t) / s(t)^\\top A  s(t) \\\\\n",
    "& = & - s(t)^\\top g(t) / s(t)^\\top A  s(t) \\\\\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of the conjugate directions $s(t)$\n",
    "\n",
    "The search directions have the following form\n",
    "\\begin{eqnarray*}\n",
    "s(t)  & = & -g(t) + \\sum_{i=0}^{t-1} c_{i}(t) s(i)\n",
    "\\end{eqnarray*}\n",
    "In a sense, we use the current gradient and a linear combination of past search directions.\n",
    "Before we derive how the coefficients $c_{i}(t)$ are found, we need some results.\n",
    "\n",
    "The update has the form\n",
    "\\begin{eqnarray*}\n",
    "x(t+1) & = & x(t) + \\gamma(t) s(t) \n",
    "\\end{eqnarray*}\n",
    "This leads to the identity about the difference of two consecutive gradients\n",
    "\\begin{eqnarray*}\n",
    "A x(t+1) &=& A x(t) + \\gamma(t) A s(t)  \\\\\n",
    "g(t+1)-g(t) & = & \\gamma(t) A s(t) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "### Orthogonality of $s(t)$ and $g(t+1)$\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "A x(t+1) &=& A x(t) + \\gamma(t) A s(t)\\\\\n",
    "g(t+1) &=& g(t) - \\frac{s(t)^\\top g(t)}{s(t)^\\top A  s(t)}  A s(t)\\\\\n",
    "s(t)^\\top g(t+1) &=& s(t)^\\top g(t) - \\frac{s(t)^\\top g(t)}{s(t)^\\top A  s(t)} s(t)^\\top A s(t) = 0 \n",
    "\\end{eqnarray*}\n",
    "\n",
    "### Orthogonality of $s(i)$ and $g(t+1)$ for $i<t$\n",
    "\n",
    "For $i<t$, if we proceed similarly,\n",
    "\\begin{eqnarray*}\n",
    "A x(t+1) &=& A x(t) + \\gamma(t) A s(t) \\\\\n",
    "s(i)^\\top g(t+1) &=& s(i)^\\top g(t) + \\gamma(t) s(i)^\\top A s(t) \\\\\n",
    "s(i)^\\top g(t+1) &=& s(i)^\\top g(t)  \\\\\n",
    "0  &=& s(i)^\\top (g(t+1) - g(t)) \\\\ \n",
    "\\end{eqnarray*}\n",
    "But actually we have a more powerful result where $ s(i)^\\top  g(t+1) = s(i)^\\top  g(t) = 0$. To see this, consider\n",
    "the solution $x(t+1)$ at time $t+1$ as a function of a past solution at $i+1$\n",
    "%\\label{eq:orth2}\n",
    "\\begin{eqnarray*}\n",
    "x(t+1) & = & x(i+1) + \\sum_{k=i+1}^{t} \\gamma(k) s(k) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "s(i)^\\top A x(t+1) & = & s(i)^\\top A x(i+1) + s(i)^\\top A \\sum_{k=i+1}^{t} \\gamma(k) s(k) \\nonumber \\\\\n",
    "s(i)^\\top g(t+1) & = & s(i)^\\top g(i+1) = 0 \\label{eq:orth2} \n",
    "\\end{eqnarray*}\n",
    "Here, \\ref{eq:orth2} follows from \\ref{eq:orth1}\n",
    "\n",
    "### Orthogonality of $g(i)$ and $g(t)$ for $i<t$\n",
    "\n",
    "We have the identity\n",
    "\\begin{eqnarray*}\n",
    "-g(i) & = &  s(i) - \\sum_{j=0}^{i-1} c_j(i) s(j) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "Multiply both sides by $g(t)^\\top$ for some $i<t$\n",
    "\\begin{eqnarray*}\n",
    "- g(t)^\\top g(i) & = &  g(t)^\\top s(i) - \\sum_{j=0}^{i-1} c_j(i) g(t)^\\top s(j) \\\\\n",
    "& = & 0\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of $c_i(t)$\n",
    "\n",
    "In general, the gradient at time $t$ is given\n",
    "\\begin{eqnarray*}\n",
    "-g(t) =  s(t) - \\sum_{j=0}^{t-1} c_j(t) s(j)\n",
    "\\end{eqnarray*}\n",
    "Multiplying both sides with $s(i)^\\top A$ for some $i<t$ results in\n",
    "\\begin{eqnarray*}\n",
    "-s(i)^\\top A g(t) &=&  s(i)^\\top A s(t) - \\sum_{j=0}^{t-1} c_j(t) s(i)^\\top A s(j) \\\\\n",
    "-s(i)^\\top A g(t) &=&  0 - c_i(t) s(i)^\\top A s(i) \\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "This implies that  \n",
    "\\begin{eqnarray*}\n",
    "c_i(t)  =   \\frac{s(i)^\\top A g(t)}{s(i)^\\top A s(i)}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "But this coefficients can be further simplified. From (\\ref{eq:diffg}) we have $g(i+1)-g(i) = \\gamma(i) A s(i)$ we obtain\n",
    "\\begin{eqnarray*}\n",
    "c_i(t)  =   \\frac{(g(i+1)-g(i))^\\top g(t)}{(g(i+1)-g(i))^\\top s(i)}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "This implies that for $i<t-1$ we have\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "c_i(t)  =   \\frac{g(i+1)^\\top g(t)-g(i)^\\top g(t)}{(g(i+1)-g(i))^\\top s(i)} = 0\n",
    "\\end{eqnarray*}\n",
    "\n",
    "For $i=t-1$ we have\n",
    "\\begin{eqnarray*}\n",
    "c_{t-1}(t) & = &  \\frac{(g(t)-g(t-1))^\\top g(t)}{(g(t)-g(t-1))^\\top s(t-1)} \\\\\n",
    " & = &  \\frac{g(t)^\\top g(t)}{g(t)^\\top s(t-1)-g(t-1)^\\top s(t-1)} \\\\\n",
    " & = &  \\frac{g(t)^\\top g(t)}{-g(t-1)^\\top s(t-1)} \\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "\n",
    "This leads to the following update:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "s(t) & = & -g(t) + c_{t-1}(t) s(t-1) \\\\\n",
    "& = & -g(t) + \\frac{g(t)^\\top g(t)}{-g(t-1)^\\top s(t-1)} s(t-1) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "This udate can be further simplified. Consider, the update for the previous time step\n",
    "\\begin{eqnarray*}\n",
    "s(t-1) & = & -g(t-1) + c_{t-2}(t-1) s(t-2) \n",
    "\\end{eqnarray*}\n",
    "We have\n",
    "\\begin{eqnarray*}\n",
    "-g(t-1)^\\top s(t-1) &=& g(t-1)^\\top g(t-1) - c_{t-2}(t-1) g(t-1)^\\top s(t-2) \\\\\n",
    "& =& g(t-1)^\\top g(t-1) \\\\\n",
    "c_{t-1}(t) &=& \\frac{g(t)^\\top g(t)}{g(t-1)^\\top g(t-1)}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "So the search direction has the simple expression in terms of the gradients\n",
    "\\begin{eqnarray*}\n",
    "s(t) & = & -g(t) + \\frac{g(t)^\\top g(t)}{g(t-1)^\\top g(t-1)} s(t-1) \n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Algorithm\n",
    "In general, we wish to solve $Ax = b$\n",
    "\n",
    "\n",
    "Select $x_0$\n",
    "\n",
    "For $t=0,1,\\dots$\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "g(t) & = & A x(t) - b\n",
    "\\end{eqnarray*}\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "c_{t-1}(t) & = & \\frac{g(t)^\\top g(t)}{g(t-1)^\\top g(t-1)}\\\\\n",
    "s(t) & = & -g(t) + c_{t-1}(t) s(t-1)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\gamma(t) & = & - s(t)^\\top g(t) / s(t)^\\top A  s(t) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "x(t+1) & = & x(t) + \\gamma(t) s(t)  \n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate a random problem\n",
    "N = 20\n",
    "#randn('seed', 1);\n",
    "\n",
    "A = np.matrix(np.random.randn(N,5))\n",
    "A = A*A.T + 0.01*np.eye(N)\n",
    "b = np.matrix(np.random.randn(N,1))\n",
    "\n",
    "#x_true = A\\b;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<ipython-input-1-e6258eac4323>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-e6258eac4323>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    x_true = A\\b;\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "%% Conjugate Gradients\n",
    "x = randn(N,1);\n",
    "s_past = zeros(N,1);\n",
    "gt_g_past = 1; % avoid NaN\n",
    "\n",
    "for t=1:N-1,\n",
    "    % Gradient\n",
    "    g = A*x - b;\n",
    "    \n",
    "    % Search direction\n",
    "    gt_g = g'*g; \n",
    "    c = gt_g/gt_g_past;\n",
    "    s = -g + c*s_past;\n",
    "    \n",
    "    % Stepsize\n",
    "    gam = - s'*g/(s'*A*s);\n",
    "    \n",
    "    % Update\n",
    "    x = x + gam*s;\n",
    "    \n",
    "    [x x_true]'\n",
    "    pause\n",
    "    s_past = s;\n",
    "    gt_g_past = gt_g;\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
