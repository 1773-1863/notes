{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hidden Markov Models\n",
    "\n",
    "### Ali Taylan Cemgil, Bogazici University\n",
    "\n",
    "The latex equations on the Github version do not render well. Please work on a clone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cemgil/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "#import pygraphviz\n",
    "import pyparsing\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from IPython.display import Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABO8AAAEhCAYAAAAnPIRLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8g4AAAAAAACw1P8Da1xSRFogegMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dfd8ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def makeDBN(inter, intra, T, labels):\n",
    "    \"\"\"Unfold a graph for T time slices\"\"\"\n",
    "    N = max(max([i for i,j in inter]),max([j for i,j in inter]))+1\n",
    "\n",
    "    G = np.zeros((N*T,N*T))\n",
    "    pos = []\n",
    "    all_labels = []\n",
    "    for n in range(N):\n",
    "        pos.append((0,-n))\n",
    "        all_labels.append('$'+labels[n]+'_{'+str(0+1)+\"}\"+'$')\n",
    "        \n",
    "    for e in inter:\n",
    "        s,d = e\n",
    "        G[s,d] = 1\n",
    "\n",
    "    for t in range(1,T):\n",
    "        for n in range(N):\n",
    "            pos.append((t,-n))\n",
    "            all_labels.append('$'+labels[n]+'_{'+str(t+1)+\"}\"+'$')\n",
    "\n",
    "        for e in inter:\n",
    "            s,d = e\n",
    "            s = s + N*t\n",
    "            d = d + N*t\n",
    "            G[s,d] = 1\n",
    "        \n",
    "        for e in intra:\n",
    "            s,d = e\n",
    "            s = s + N*(t-1)\n",
    "            d = d + N*t\n",
    "            G[s,d] = 1\n",
    "    return G,pos,all_labels\n",
    "\n",
    "#inter = [(0,1),(1,2),(2,3)]\n",
    "#intra = [(0,0),(1,1),(0,1),(0,2)]\n",
    "#variable_names = [\"r\",\"z\",\"x\", \"y\"] \n",
    "inter = [(0,1)]\n",
    "intra = [(0,0)]\n",
    "variable_names = [\"x\", \"y\"] \n",
    "T = 5\n",
    "\n",
    "A, pos, label_list = makeDBN(inter, intra, T, variable_names)\n",
    "\n",
    "G = nx.DiGraph(A)\n",
    "labels = {i: s for i,s in enumerate(label_list)}\n",
    "plt.figure(figsize=(12,2.5))\n",
    "nx.draw(G, pos, node_color=\"white\", node_size=2500, labels=labels, font_size=24, arrows=True)\n",
    "#nx.draw_graphviz(G,node_size=500, labels=labels, font_size=24, arrows=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Pass\n",
    "\n",
    "\\begin{eqnarray}\n",
    "p(y_{1:K}) & = & \\sum_{x_{1:K}} p(y_{1:K}|x_{1:K}) p(x_{1:K}) \\\\\n",
    "& = &  \\underbrace{\\sum_{x_K} p(y_K | x_K ) \\sum_{x_{K-1}} p(x_K|x_{K-1})  \\dots \\sum_{x_{2}} p(x_3|x_{2})\n",
    "\\underbrace{ p(y_{2}|x_{2}) \\overbrace{ \\sum_{x_{1}} p(x_2|x_{1})\n",
    "\\underbrace{ p(y_{1}|x_{1}) \\overbrace{ p(x_1)}^{\\alpha_{1|0}}}_{\\alpha_{1|1}}\n",
    "}^{\\alpha_{2|1}} }_{\\alpha_{2|2}}}_{\\alpha_{K|K}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\alpha_{1|0} & \\equiv & p(x_1)\n",
    "\\end{eqnarray}\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\alpha_{k|k} & \\equiv & p(y_{1:k}, x_k)\n",
    "\\end{eqnarray}\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\alpha_{k|k-1}  & \\equiv & p(y_{1:k-1}, x_k)\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "\n",
    "For $k=1, 2, \\dots, K$\n",
    "\n",
    "__Predict__\n",
    "\n",
    "$k=1$:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\alpha_{1|0}(x_1) = p(x_1)\n",
    "\\end{eqnarray}\n",
    "\n",
    "$k>1$:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "{\\alpha_{k|k-1}(x_k)} & = & p(y_{1:k-1}, x_k) = \\sum_{x_{k-1}} p(x_k| x_{k-1}) p(y_{1:k-1}, x_{k-1}) \\\\\n",
    "& = & \\sum_{x_{k-1}} p(x_k| x_{k-1}) { \\alpha_{k-1|k-1}(x_{k-1}) }\n",
    "\\end{eqnarray}\n",
    "\n",
    "__Update__\n",
    "\n",
    "\\begin{eqnarray}\n",
    "{\\alpha_{k|k}(x_k) } & = & p(y_{1:k}, x_k) = p(y_k | x_k) p(y_{1:k-1}, x_k) \\\\\n",
    " & = & p(y_k | x_k) {\\alpha_{k|k-1}(x_k)}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Pass\n",
    "\n",
    "\n",
    "\\begin{eqnarray}\n",
    "p(y_{1:K}) & = &  \\sum_{x_1} p(x_1) p(y_1 | x_1 )\n",
    "%underbrace{\\sum_{x_2} p(x_2|x_{1}) p(y_2 | x_2 )}_{\\beta_1}\n",
    "\\dots\n",
    "\\underbrace{ \\sum_{x_{K-1}} p(x_{K-1}|x_{K-2}) p(y_{K-1} | x_{K-1} )\n",
    "\\underbrace{ \\sum_{x_K} p(x_K|x_{K-1}) p(y_K | x_K )\n",
    "\\underbrace{{\\pmb 1}}_{\\beta_{K|K+1}}}_{\\beta_{K-1|K}}}_{\\beta_{K-2|K-1}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\beta_{k|k+1}(x_k) & \\equiv & p(y_{k+1:K}| x_k) \\\\\n",
    "\\beta_{k|k}(x_k) & \\equiv & p(y_{k:K}| x_k)\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "For $k=K, K-1, \\dots, 1$\n",
    "\n",
    "'Postdict' : (Backward Prediction)\n",
    "\n",
    "$k=K$\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\beta_{K|K+1}(x_K) & = & \\mathbf{1} \n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "$k<K$ \n",
    "\\begin{eqnarray}\n",
    "\\beta_{k|k+1}(x_k) & = & p(y_{k+1:K}| x_k) = \\sum_{x_{k+1}} p(x_{k+1}| x_{k}) p(y_{k+1:K}| x_{k+1}) \\\\\n",
    "& = & \\sum_{x_{k+1}} p(x_{k+1}| x_{k}) \\beta_{k+1|k+1}(x_{k+1}) \n",
    "\\end{eqnarray}\n",
    "\n",
    "Update\n",
    "\\begin{eqnarray}\n",
    "\\beta_{k|k}(x_k)  & = & p(y_{k:K}| x_k) = p(y_k | x_k) p(y_{k+1:K}| x_k) \\\\\n",
    " & = & p(y_k | x_k) {\\beta_{k|k+1}(x_k)}\n",
    "\\end{eqnarray}\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerically Stable computation of $\\log(\\sum_i \\exp (l_i ) ))$\n",
    "\n",
    "Derivation\n",
    "\n",
    "\\begin{eqnarray}\n",
    "L & = & \\log(\\sum_i \\exp (l_i) ) \n",
    " =   \\log(\\sum_i \\exp (l_i) \\frac{\\exp(l^*)}{\\exp(l^*)} ) \\\\\n",
    "& = &  \\log( \\exp(l^*) \\sum_i \\exp (l_i - l^*) ) \\\\\n",
    "& = &  l^* + \\log( \\sum_i \\exp (l_i - l^*) )\n",
    "\\end{eqnarray}\n",
    "\n",
    "Choose $l^*  =  \\max_i l_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Naive evaluation  :', -inf)\n",
      "('Numerically stable:', array([-1000.]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def log_sum_exp_naive(l):\n",
    "    return np.log(np.sum(np.exp(l)))\n",
    "\n",
    "def log_sum_exp(l, axis=0):\n",
    "    l_star = np.max(l, axis=axis, keepdims=True)\n",
    "    return l_star + np.log(np.sum(np.exp(l - l_star),axis=axis,keepdims=True)) \n",
    "    \n",
    "    \n",
    "l = np.array([-1000, -10000])\n",
    "\n",
    "print('Naive evaluation  :', log_sum_exp_naive(l))\n",
    "print('Numerically stable:', log_sum_exp(l))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# An implementation of the forward backward algorithm\n",
    "# For numerical stability, we calculate everything in the log domain\n",
    "\n",
    "def normalize_exp(log_P, axis=None):\n",
    "    a = np.max(log_P, keepdims=True, axis=axis)\n",
    "    P = normalize(np.exp(log_P - a), axis=axis)\n",
    "    return P\n",
    "\n",
    "\n",
    "def normalize(A, axis=None):\n",
    "    Z = np.sum(A, axis=axis,keepdims=True)\n",
    "    idx = np.where(Z == 0)\n",
    "    Z[idx] = 1\n",
    "    return A/Z\n",
    "\n",
    "def randgen(pr, N=1): \n",
    "    L = len(pr)\n",
    "    return np.random.choice(range(L), size=N, replace=True, p=pr)\n",
    "\n",
    "def predict(A, lp):\n",
    "    lstar = np.max(lp)\n",
    "    return lstar + np.log(np.dot(A,np.exp(lp-lstar)))\n",
    "\n",
    "def postdict(A, lp):\n",
    "    lstar = np.max(lp)\n",
    "    return lstar + np.log(np.dot(np.exp(lp-lstar), A))\n",
    "\n",
    "def update(y, logB, lp):\n",
    "    return logB[y,:] + lp\n",
    "\n",
    "# Generate Parameter\n",
    "S = 3\n",
    "R = 5\n",
    "A = np.random.dirichlet(0.7*np.ones(S),S).T\n",
    "B = np.random.dirichlet(0.7*np.ones(R),S).T\n",
    "p = np.random.dirichlet(0.7*np.ones(S)).T\n",
    "\n",
    "logA = np.log(A)\n",
    "logB = np.log(B)\n",
    "\n",
    "# Generate Data\n",
    "\n",
    "# Number of steps\n",
    "T = 100\n",
    "\n",
    "x = np.zeros(T,int)\n",
    "y = np.zeros(T,int)\n",
    "for t in range(T):\n",
    "    if t==0:\n",
    "        x[t] = randgen(p)\n",
    "    else:\n",
    "        x[t] = randgen(A[:,x[t-1]])\n",
    "    \n",
    "    y[t] = randgen(B[:,x[t]])\n",
    "    \n",
    "# Forward Pass\n",
    "\n",
    "# Python indexes starting from zero so\n",
    "# log \\alpha_{k|k} will be in log_alpha[:,k-1]\n",
    "# log \\alpha_{k|k-1} will be in log_alpha_pred[:,k-1]\n",
    "log_alpha  = np.zeros((S, T))\n",
    "log_alpha_pred = np.zeros((S, T))\n",
    "for k in range(T):\n",
    "    if k==0:\n",
    "        log_alpha_pred[:,0] = np.log(p)\n",
    "    else:\n",
    "        log_alpha_pred[:,k] = predict(A, log_alpha[:,k-1])\n",
    "    \n",
    "    log_alpha[:,k] = update(y[k], logB, log_alpha_pred[:,k])\n",
    "    \n",
    "# Backward Pass\n",
    "log_beta  = np.zeros((S, T))\n",
    "log_beta_post = np.zeros((S, T))\n",
    "\n",
    "for k in range(T-1,-1,-1):\n",
    "    if k==T-1:\n",
    "        log_beta_post[:,k] = np.zeros(S)\n",
    "    else:\n",
    "        log_beta_post[:,k] = postdict(A, log_beta[:,k+1])\n",
    "    \n",
    "    log_beta[:,k] = update(y[k], logB, log_beta_post[:,k])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing - Forward Backward Algorithm (Two filter formulation)\n",
    "\\begin{eqnarray}\n",
    "p(y_{1:K}, x_k) & = & p(y_{1:k}, x_k) p(y_{k+1:K} | x_k) \\\\\n",
    "& = & {\\alpha_{k|k}(x_k) } {\\beta_{k|k+1}(x_k)} \\\\\n",
    "& \\equiv & \\gamma_k(x_k)\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965\n",
      "  -145.93568965 -145.93568965 -145.93568965 -145.93568965 -145.93568965]]\n"
     ]
    }
   ],
   "source": [
    "# Smoother check\n",
    "# All numbers must be equal to the marginal likelihood p(y_{1:K})\n",
    "\n",
    "log_gamma = log_alpha + log_beta_post\n",
    "print(log_sum_exp(log_gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing (Forward filtering - Backward smoothing), The Correction Smoother\n",
    "\n",
    "Suppose we have computed the filtered quantities $p(x_t| y_{1:t})$ via the forward pass. The forward-backward algorithm requires us to store all observations. For batch settings, this is OK however when datapoints are arriving indeed sequentially, this may be not desired.  \n",
    "\n",
    "We will derive a recursive algorithm to compute the marginals $p(x_t | y_{1:T})$.\n",
    "\n",
    "Note that if we calculate instead the so-called __pairwise__ marginal $p(x_t, x_{t+1} | y_{1:T} )$, we can get by simple marginalization\n",
    "\n",
    "\\begin{align}\n",
    "p(x_t | y_{1:T}) & =  \\sum_{x_{t+1}} p(x_t, x_{t+1} | y_{1:T} )  & \\text{Definition} \n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "p(x_t, x_{t+1} | y_{1:T} ) & =   p(x_{t} |x_{t+1}, y_{1:t},y_{t+1:T} ) p(x_{t+1}|y_{1:T} ) & \\text{Factorize} \\\\\n",
    "& =   p(x_{t} |x_{t+1}, y_{1:t} ) p(x_{t+1}|y_{1:T} ) & \\text{Conditional Independence}\\\\\n",
    "  & =  \\frac{p(x_{t}, x_{t+1}| y_{1:t} )}{p(x_{t+1}| y_{1:t} )} p(x_{t+1}|y_{1:T} ) & \\text{Definition of Conditional} \n",
    "\\end{align}\n",
    "\n",
    "This update has the form:\n",
    "\\begin{eqnarray}\n",
    "\\text{New Pairwise Marginal}_{t,t+1} & = & \\frac{\\text{Old Pairwise Marginal}_{t,t+1}}{\\text{Old Marginal}_{t+1}} \\times {\\text{New Marginal}_{t+1}} \\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "The old pairwise marginal can be simply calculated from the filtered marginals as\n",
    "\n",
    "\\begin{align}\n",
    "p(x_{t}, x_{t+1}| y_{1:t} ) & =  p(x_{t+1} | x_t,  y_{1:t} ) p(x_t | y_{1:t}) & \\text{Definition} \\\\\n",
    "& =  p(x_{t+1} | x_t ) p(x_t | y_{1:t}) & \\text{Conditional Independence} \\\\\n",
    "& = \\text{Transition Model} \\times \\text{Filtering distribution} \n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "The correction smoother calculates a factorisation of the posterior of form\n",
    "\n",
    "\\begin{eqnarray}\n",
    "p(x_{1:T}|y_{1:T}) & = & \\frac{\\prod_{t=1}^{T-1} p(x_{t}, x_{t+1} | y_{1:T}) }{ \\prod_{t=2}^{T-1} p(x_{t} | y_{1:T}) }\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABkkAAAEwCAYAAAATnJYiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dfcb2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correction Smoother\n",
    "# For numerical stability, we calculate everything in the log domain\n",
    "log_gamma_corr = np.zeros_like(log_alpha)\n",
    "log_gamma_corr[:,T-1] = log_alpha[:,T-1]\n",
    "\n",
    "for k in range(T-2,-1,-1):\n",
    "    log_old_pairwise_marginal = log_alpha[:,k].reshape(1,S) + logA \n",
    "    log_old_marginal = predict(A, log_alpha[:,k])\n",
    "    log_new_pairwise_marginal = log_old_pairwise_marginal + log_gamma_corr[:,k+1].reshape(S,1) - log_old_marginal.reshape(S,1)\n",
    "    log_gamma_corr[:,k] = log_sum_exp(log_new_pairwise_marginal, axis=0).reshape(S)\n",
    "    \n",
    "\n",
    "# Verify that result coincide\n",
    "\n",
    "gam = normalize_exp(log_gamma, axis=0)\n",
    "gam_corr = normalize_exp(log_gamma_corr, axis=0)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(gam, interpolation='nearest')\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(gam_corr, interpolation='nearest')\n",
    "\n",
    "plt.show()\n",
    "#print(log_gamma)\n",
    "#print(log_gamma_corr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Implementation of the HMM in Python\n",
    "\n",
    "We will integrate filtering, smoothing and training functionality into an HMM object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some utility functions\n",
    "\n",
    "def randgen(pr, N=1): \n",
    "    L = len(pr)\n",
    "    return int(np.random.choice(range(L), size=N, replace=True, p=pr))\n",
    "\n",
    "def log_sum_exp(l, axis=0):\n",
    "    l_star = np.max(l, axis=axis, keepdims=True)\n",
    "    return l_star + np.log(np.sum(np.exp(l - l_star),axis=axis,keepdims=True)) \n",
    "\n",
    "def normalize_exp(log_P, axis=None):\n",
    "    a = np.max(log_P, keepdims=True, axis=axis)\n",
    "    P = normalize(np.exp(log_P - a), axis=axis)\n",
    "    return P\n",
    "\n",
    "def normalize(A, axis=None):\n",
    "    Z = np.sum(A, axis=axis,keepdims=True)\n",
    "    idx = np.where(Z == 0)\n",
    "    Z[idx] = 1\n",
    "    return A/Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.02674609  39.00988497  11.51886325]\n",
      " [ 28.56702027  12.61791804  77.10422239]\n",
      " [ 22.49233802  66.31615127  36.34685571]]\n",
      "[[  5.02674609  39.00988497  11.51886325]\n",
      " [ 28.56702027  12.61791804  77.10422239]\n",
      " [ 22.49233802  66.31615127  36.34685571]]\n"
     ]
    }
   ],
   "source": [
    "class HMM(object):\n",
    "    def __init__(self, pi, A, B):\n",
    "        # p(x_0)\n",
    "        self.pi = pi\n",
    "        # p(x_k|x_{k-1})\n",
    "        self.A = A\n",
    "        # p(y_k|x_{k})\n",
    "        self.B = B\n",
    "        # Number of possible latent states at each time\n",
    "        self.S = pi.shape[0]\n",
    "        # Number of possible observations at each time\n",
    "        self.R = B.shape[0]\n",
    "        self.logB = np.log(self.B)\n",
    "        self.logA = np.log(self.A)\n",
    "        self.logpi = np.log(self.pi)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_random_parameters(cls, S=3, R=5):\n",
    "        A = np.random.dirichlet(0.7*np.ones(S),S).T\n",
    "        B = np.random.dirichlet(0.7*np.ones(R),S).T\n",
    "        pi = np.random.dirichlet(0.7*np.ones(S)).T\n",
    "        return cls(pi, A, B)\n",
    "        \n",
    "    def __str__(self):\n",
    "        s = \"Prior:\\n\" + str(self.pi) + \"\\nA:\\n\" + str(self.A) + \"\\nB:\\n\" + str(self.B)\n",
    "        return s\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = self.__str__()\n",
    "        return s\n",
    "\n",
    "    def predict(self, lp):\n",
    "        lstar = np.max(lp)\n",
    "        return lstar + np.log(np.dot(self.A,np.exp(lp-lstar)))\n",
    "\n",
    "    def postdict(self, lp):\n",
    "        lstar = np.max(lp)\n",
    "        return lstar + np.log(np.dot(np.exp(lp-lstar), self.A))\n",
    "\n",
    "    def update(self, y, lp):\n",
    "        return self.logB[y,:] + lp\n",
    "\n",
    "    def generate_sequence(self, T=10):\n",
    "    # T: Number of steps\n",
    "\n",
    "        x = np.zeros(T, int)\n",
    "        y = np.zeros(T, int)\n",
    "\n",
    "        for t in range(T):\n",
    "            if t==0:\n",
    "                x[t] = randgen(self.pi)\n",
    "            else:\n",
    "                x[t] = randgen(self.A[:,x[t-1]])    \n",
    "            y[t] = randgen(self.B[:,x[t]])\n",
    "    \n",
    "        return y, x\n",
    "\n",
    "    def forward(self, y):\n",
    "        T = len(y)\n",
    "        \n",
    "        # Forward Pass\n",
    "\n",
    "        # Python indexes starting from zero so\n",
    "        # log \\alpha_{k|k} will be in log_alpha[:,k-1]\n",
    "        # log \\alpha_{k|k-1} will be in log_alpha_pred[:,k-1]\n",
    "        log_alpha  = np.zeros((self.S, T))\n",
    "        log_alpha_pred = np.zeros((self.S, T))\n",
    "        for k in range(T):\n",
    "            if k==0:\n",
    "                log_alpha_pred[:,0] = self.logpi\n",
    "            else:\n",
    "                log_alpha_pred[:,k] = self.predict(log_alpha[:,k-1])\n",
    "\n",
    "            log_alpha[:,k] = self.update(y[k], log_alpha_pred[:,k])\n",
    "            \n",
    "        return log_alpha, log_alpha_pred\n",
    "            \n",
    "    def backward(self, y):\n",
    "        # Backward Pass\n",
    "        T = len(y)\n",
    "        log_beta  = np.zeros((self.S, T))\n",
    "        log_beta_post = np.zeros((self.S, T))\n",
    "\n",
    "        for k in range(T-1,-1,-1):\n",
    "            if k==T-1:\n",
    "                log_beta_post[:,k] = np.zeros(self.S)\n",
    "            else:\n",
    "                log_beta_post[:,k] = self.postdict(log_beta[:,k+1])\n",
    "\n",
    "            log_beta[:,k] = self.update(y[k], log_beta_post[:,k])\n",
    "\n",
    "        return log_beta, log_beta_post\n",
    "        \n",
    "    def forward_backward_smoother(self, y):\n",
    "        log_alpha, log_alpha_pred = self.forward(y)\n",
    "        log_beta, log_beta_post = self.backward(y)\n",
    "        \n",
    "        log_gamma = log_alpha + log_beta_post\n",
    "        return log_gamma\n",
    "        \n",
    "    def correction_smoother(self, y):\n",
    "        # Correction Smoother\n",
    "\n",
    "        log_alpha, log_alpha_pred = self.forward(y)\n",
    "        T = len(y)\n",
    "        \n",
    "        # For numerical stability, we calculate everything in the log domain\n",
    "        log_gamma_corr = np.zeros_like(log_alpha)\n",
    "        log_gamma_corr[:,T-1] = log_alpha[:,T-1]\n",
    "\n",
    "        C2 = np.zeros((self.S, self.S))\n",
    "        C3 = np.zeros((self.R, self.S))\n",
    "        C3[y[-1],:] = normalize_exp(log_alpha[:,T-1])\n",
    "        for k in range(T-2,-1,-1):\n",
    "            log_old_pairwise_marginal = log_alpha[:,k].reshape(1,self.S) + self.logA \n",
    "            log_old_marginal = self.predict(log_alpha[:,k])\n",
    "            log_new_pairwise_marginal = log_old_pairwise_marginal + log_gamma_corr[:,k+1].reshape(self.S,1) - log_old_marginal.reshape(self.S,1)\n",
    "            log_gamma_corr[:,k] = log_sum_exp(log_new_pairwise_marginal, axis=0).reshape(self.S)\n",
    "            C2 += normalize_exp(log_new_pairwise_marginal)\n",
    "            C3[y[k],:] += normalize_exp(log_gamma_corr[:,k])\n",
    "        C1 = normalize_exp(log_gamma_corr[:,0])\n",
    "        return log_gamma_corr, C1, C2, C3\n",
    "    \n",
    "    def forward_only_SS(self, y, V=None):\n",
    "        # Forward only estimation of expected sufficient statistics\n",
    "        T = len(y)\n",
    "        \n",
    "        if V is None:\n",
    "            V1  = np.eye((self.S))\n",
    "            V2  = np.zeros((self.S,self.S,self.S))\n",
    "            V3  = np.zeros((self.R,self.S,self.S))\n",
    "        else:\n",
    "            V1, V2, V3 = V\n",
    "            \n",
    "        I_S1S = np.eye(self.S).reshape((self.S,1,self.S))\n",
    "        I_RR = np.eye(self.R)\n",
    "        \n",
    "        for k in range(T):\n",
    "            if k==0:\n",
    "                log_alpha_pred = self.logpi\n",
    "            else:\n",
    "                log_alpha_pred = self.predict(log_alpha)\n",
    "\n",
    "            if k>0:\n",
    "                #print(self.S, self.R)\n",
    "                #print(log_alpha)\n",
    "                # Calculate p(x_{k-1}|y_{1:k-1}, x_k) \n",
    "                lp = np.log(normalize_exp(log_alpha)).reshape(self.S,1) + self.logA.T    \n",
    "                P = normalize_exp(lp, axis=0)\n",
    "\n",
    "                # Update\n",
    "                V1 = np.dot(V1, P)             \n",
    "                V2 = np.dot(V2, P) + I_S1S*P.reshape((1,self.S,self.S))    \n",
    "                V3 = np.dot(V3, P) + I_RR[:,y[k-1]].reshape((self.R,1,1))*P.reshape((1,self.S,self.S))    \n",
    "\n",
    "            log_alpha = self.update(y[k], log_alpha_pred)    \n",
    "            p_xT = normalize_exp(log_alpha)    \n",
    "\n",
    "        C1 = np.dot(V1, p_xT.reshape(self.S,1))\n",
    "        C2 = np.dot(V2, p_xT.reshape(1,self.S,1)).reshape((self.S,self.S))\n",
    "        C3 = np.dot(V3, p_xT.reshape(1,self.S,1)).reshape((self.R,self.S))\n",
    "        C3[y[-1],:] +=  p_xT\n",
    "        \n",
    "        ll = log_sum_exp(log_alpha)\n",
    "        \n",
    "        return C1, C2, C3, ll, (V1, V2, V3)\n",
    "\n",
    "    def train_EM(self, y, EPOCH=10):\n",
    "        \n",
    "        LL = np.zeros(EPOCH)\n",
    "        for e in range(EPOCH):\n",
    "            C1, C2, C3, ll, V = self.forward_only_SS(y)\n",
    "            LL[e] = ll\n",
    "            p = normalize(C1 + 0.1, axis=0).reshape(S)\n",
    "            #print(p,np.size(p))            \n",
    "            A = normalize(C2, axis=0)\n",
    "            #print(A)\n",
    "            B = normalize(C3, axis=0)\n",
    "            #print(B)\n",
    "            self.__init__(p, A, B)\n",
    "            print(ll)\n",
    "            \n",
    "        return LL\n",
    "            \n",
    "    \n",
    "    \n",
    "hm = HMM.from_random_parameters()\n",
    "\n",
    "y,x = hm.generate_sequence(300)\n",
    "\n",
    "log_alpha, log_alpha_pred = hm.forward(y)\n",
    "log_gamma = hm.forward_backward_smoother(y)\n",
    "log_gamma_corr, C1_corr, C2_corr, C3_corr = hm.correction_smoother(y)\n",
    "C1, C2, C3, ll, V = hm.forward_only_SS(y)\n",
    "\n",
    "print(C2)\n",
    "print(C2_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-360.48680062]\n",
      "[-358.46940275]\n",
      "[-358.04898554]\n",
      "[-357.68403766]\n",
      "[-357.31790382]\n",
      "[-356.92734819]\n",
      "[-356.49771349]\n",
      "[-356.02447298]\n",
      "[-355.51680383]\n",
      "[-354.9987681]\n",
      "[-354.50448594]\n",
      "[-354.06692107]\n",
      "[-353.70591235]\n",
      "[-353.42336884]\n",
      "[-353.2078141]\n",
      "[-353.04300448]\n",
      "[-352.9143951]\n",
      "[-352.81147328]\n",
      "[-352.72737612]\n",
      "[-352.65768538]\n",
      "[-352.59940025]\n",
      "[-352.55031038]\n",
      "[-352.50867409]\n",
      "[-352.47306606]\n",
      "[-352.44230291]\n",
      "[-352.41540019]\n",
      "[-352.39154125]\n",
      "[-352.37005099]\n",
      "[-352.35037279]\n",
      "[-352.33204826]\n",
      "[-352.31469997]\n",
      "[-352.29801697]\n",
      "[-352.28174302]\n",
      "[-352.26566723]\n",
      "[-352.24961673]\n",
      "[-352.2334512]\n",
      "[-352.21705872]\n",
      "[-352.20035285]\n",
      "[-352.18327039]\n",
      "[-352.1657698]\n",
      "[-352.14782982]\n",
      "[-352.12944811]\n",
      "[-352.11063975]\n",
      "[-352.09143543]\n",
      "[-352.07187923]\n",
      "[-352.05202609]\n",
      "[-352.03193894]\n",
      "[-352.01168567]\n",
      "[-351.99133613]\n",
      "[-351.97095934]\n",
      "[-351.95062099]\n",
      "[-351.93038147]\n",
      "[-351.91029444]\n",
      "[-351.89040592]\n",
      "[-351.87075397]\n",
      "[-351.85136879]\n",
      "[-351.83227321]\n",
      "[-351.8134834]\n",
      "[-351.79500983]\n",
      "[-351.77685826]\n",
      "[-351.75903071]\n",
      "[-351.74152648]\n",
      "[-351.72434301]\n",
      "[-351.70747666]\n",
      "[-351.69092338]\n",
      "[-351.67467927]\n",
      "[-351.65874097]\n",
      "[-351.643106]\n",
      "[-351.62777296]\n",
      "[-351.61274164]\n",
      "[-351.59801307]\n",
      "[-351.5835895]\n",
      "[-351.56947428]\n",
      "[-351.55567175]\n",
      "[-351.54218707]\n",
      "[-351.52902603]\n",
      "[-351.51619482]\n",
      "[-351.50369981]\n",
      "[-351.49154737]\n",
      "[-351.4797436]\n",
      "[-351.46829415]\n",
      "[-351.45720404]\n",
      "[-351.44647749]\n",
      "[-351.43611775]\n",
      "[-351.42612704]\n",
      "[-351.41650641]\n",
      "[-351.40725569]\n",
      "[-351.39837349]\n",
      "[-351.38985717]\n",
      "[-351.38170284]\n",
      "[-351.37390545]\n",
      "[-351.36645882]\n",
      "[-351.35935573]\n",
      "[-351.35258801]\n",
      "[-351.34614664]\n",
      "[-351.34002188]\n",
      "[-351.33420335]\n",
      "[-351.32868019]\n",
      "[-351.32344112]\n",
      "[-351.31847461]\n"
     ]
    }
   ],
   "source": [
    "LL = hm.train_EM(y, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAFkCAYAAABvkjJwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111c50e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(LL)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-360.54624298 -361.94347477 -364.59488744 -365.35650859 -361.07837215\n",
      "  -365.27484809 -363.94347127 -361.23302215 -365.24377226 -361.51619134\n",
      "  -361.2171339  -364.12901276 -365.07022809 -361.46636875 -361.31649044\n",
      "  -361.76181693 -360.87525952 -361.71775743 -364.67117917 -364.80592291\n",
      "  -365.09113411 -361.14619642 -364.12241058 -365.39149262 -361.0744572\n",
      "  -365.40622211 -361.51565006 -361.20031878 -365.26493805 -364.60345651\n",
      "  -365.55283845 -360.72268719 -365.59907042 -364.63319806 -364.85853127\n",
      "  -364.66187234 -365.25199502 -361.07801938 -365.76004356 -361.05879986\n",
      "  -365.66428882 -361.13292641 -365.28543983 -361.22815081 -364.92034977\n",
      "  -364.75927689 -364.79386247 -364.66700448 -365.50435055 -360.72562131\n",
      "  -366.10738215 -361.0490041  -365.42084673 -363.75351424 -362.17557231\n",
      "  -360.73283837 -364.5053768  -364.83393147 -364.96346377 -361.35307583\n",
      "  -361.56947634 -361.32956844 -361.51999971 -361.75033999 -360.78000008\n",
      "  -365.51827159 -364.67144241 -364.74649809 -365.15279844 -361.11497013\n",
      "  -365.17212082 -365.03559754 -361.17537615 -365.30861582 -361.11747511\n",
      "  -365.21026878 -364.70449896 -364.74281661 -365.08305252 -361.24951186\n",
      "  -361.54417756 -364.7357743  -364.83362568 -364.73454826 -364.74131863\n",
      "  -365.05698988 -361.23204357 -364.9135368  -364.92032532 -361.57059242\n",
      "  -361.18902362 -365.16799622 -364.99656165 -361.22563881 -364.94680621\n",
      "  -363.74505298 -364.98202792 -364.66724492 -364.80815911 -364.87604131\n",
      "  -361.58487508 -361.24439637 -362.02924177 -361.08999224 -365.63709446\n",
      "  -361.24077146 -361.38303226 -364.2963794  -361.27277319 -361.83281571\n",
      "  -361.23051407 -361.67474438 -363.70758234 -365.0104913  -364.95074388\n",
      "  -361.28278074 -361.52327143 -364.74566416 -364.83835559 -364.72102544\n",
      "  -364.77670677 -364.75008783 -364.7608541  -364.76001557 -364.75135874\n",
      "  -364.77426817 -364.72455332 -365.06100408 -361.23814916 -364.90350422\n",
      "  -364.80876306 -364.69756561 -365.11500647 -361.23368196 -361.63448119\n",
      "  -361.25058784 -365.17594175 -364.64336321 -365.22283821 -361.10431192\n",
      "  -365.16800111 -365.06549418 -361.18747211 -361.98063094 -361.10198383\n",
      "  -365.25289035 -364.9600168  -361.26193532 -364.88752937 -364.78122629\n",
      "  -364.76341422 -364.7193087  -365.08679659 -361.26195611 -361.48062392\n",
      "  -365.03640038 -361.25372845 -365.12819724 -361.30599351 -364.82797798\n",
      "  -365.2562125  -361.08689755 -365.33890739 -363.65821772 -365.03271708\n",
      "  -364.81479195 -361.5647227  -361.30622952 -361.55569638 -364.72528267\n",
      "  -364.85372608 -364.70485503 -364.98224763 -361.43297548 -361.33756281\n",
      "  -364.85092078 -365.13075184 -361.18155504 -365.19719365 -361.34116917\n",
      "  -361.29024064 -365.86694875 -360.71792379 -365.66098913 -364.58059764\n",
      "  -365.50544609 -360.77859355 -361.74738373 -364.67913031 -363.81123274\n",
      "  -364.98163968 -364.63012164 -365.22339923 -361.15410467 -362.06211837\n",
      "  -361.08485367 -365.77740818 -361.07195325 -365.16686791 -365.36861431\n",
      "  -360.73345299 -365.5396556  -364.67753003 -364.73377597 -365.19798489\n",
      "  -361.08535127 -365.74406175 -361.06086451 -365.63260198 -361.16208211\n",
      "  -364.99037944 -364.72788332 -365.06493531 -361.22883862 -364.91795318\n",
      "  -364.77046421 -364.94188334 -361.45432971 -361.39693159 -361.31263315\n",
      "  -365.43628615 -361.22054922 -361.59153054 -361.40882645 -361.52722518\n",
      "  -364.72396632 -365.27780392 -361.09371921 -365.29770162 -361.75237723\n",
      "  -360.77635672 -365.54864529 -364.64507964 -364.82170846 -364.72268774\n",
      "  -364.79026203 -364.71585802 -365.07513455 -361.22310765 -365.08551502\n",
      "  -361.53042202 -361.23436006 -365.24267652 -361.24949604 -361.574005\n",
      "  -364.71017352 -365.18500054 -361.17753512 -364.98512251 -364.67741082\n",
      "  -365.48338517 -360.72635392 -365.53663364 -364.91302747 -361.3154694\n",
      "  -364.82218023 -365.24683742 -361.09368228 -365.25510795 -364.6775373\n",
      "  -364.80011109 -364.73776144 -364.76999188 -364.74972924 -364.76856541\n",
      "  -364.74126525 -364.79219338 -364.69215381 -365.20103109 -361.10252151\n",
      "  -364.51739402 -361.17082502 -365.15552067 -364.7073669  -364.76323189\n",
      "  -364.99023031 -361.35907676 -361.54259793 -361.29308481 -364.90111795\n",
      "  -364.77611861 -364.75975476 -364.73415335 -365.0403272  -361.26340271\n",
      "  -364.86709518 -365.14477444 -361.22623401 -361.60373698 -363.94550282\n",
      "  -361.46770261 -364.73512778 -364.85757625 -363.97180014 -361.26506893\n",
      "  -364.03510909 -365.19279874 -361.31398005 -361.53686034 -361.3743101 ]\n",
      " [-363.57963374 -361.04711628 -361.8817551  -360.92012934 -362.34911626\n",
      "  -361.23902935 -361.38502518 -361.93664515 -361.29449352 -361.18911038\n",
      "  -361.99223922 -361.64947578 -361.24289977 -361.23683891 -361.92845281\n",
      "  -361.20661522 -362.59976265 -361.19580175 -361.47046332 -361.47272178\n",
      "  -361.06795204 -361.94180773 -361.94390574 -360.91049346 -362.35232496\n",
      "  -361.25943005 -361.17544879 -362.27985402 -361.09823883 -361.85173688\n",
      "  -360.82918238 -363.46702082 -361.15100585 -361.53435804 -361.2008788\n",
      "  -361.68739196 -360.93525663 -362.61879451 -360.87409335 -362.58580022\n",
      "  -360.99063587 -361.80957399 -361.14821321 -361.58395822 -361.36729972\n",
      "  -361.42419689 -361.21744374 -361.77341693 -360.83670674 -363.76046296\n",
      "  -360.84595229 -362.60562795 -361.01562996 -362.160244   -360.80974185\n",
      "  -363.35706001 -361.5090224  -361.36826537 -361.23245326 -361.44173874\n",
      "  -361.19999911 -361.82041912 -361.39748306 -361.01963285 -363.20384101\n",
      "  -361.22390023 -361.35682049 -361.55338383 -361.01262398 -362.16376707\n",
      "  -361.39921148 -361.12339834 -361.76577763 -361.02488129 -362.20747876\n",
      "  -361.2747429  -361.34484289 -361.51510294 -361.07574588 -361.88107309\n",
      "  -361.28319916 -361.49980405 -361.3225243  -361.33849634 -361.47260075\n",
      "  -361.15082297 -361.57322259 -361.39418635 -361.36762606 -361.13630109\n",
      "  -362.15414499 -361.36195945 -361.17338821 -361.61569423 -361.24092719\n",
      "  -361.78515474 -361.20906373 -361.45135001 -361.31313015 -361.40650158\n",
      "  -361.12008266 -362.24744189 -360.90023512 -362.6248892  -361.00169151\n",
      "  -361.77893446 -361.86953813 -361.26366666 -361.94931994 -361.0126244\n",
      "  -362.0946084  -361.13207776 -361.9187579  -361.31245506 -361.15551133\n",
      "  -361.81253356 -361.29730578 -361.50594293 -361.29858209 -361.39456208\n",
      "  -361.34814418 -361.36691953 -361.36517829 -361.35076527 -361.38942828\n",
      "  -361.30796058 -361.48425946 -361.15313863 -361.5540518  -361.44887105\n",
      "  -361.26172273 -361.56214032 -361.06006331 -361.89164471 -361.35270838\n",
      "  -362.09354484 -361.1667633  -361.66596125 -360.98328701 -362.17533715\n",
      "  -361.45140458 -361.04524916 -362.18190838 -360.9318204  -362.3700262\n",
      "  -361.31898924 -361.21478088 -361.52704363 -361.40452067 -361.3712153\n",
      "  -361.30060446 -361.52945005 -361.08286655 -361.8253463  -361.39620355\n",
      "  -361.23869096 -361.56970328 -361.25276184 -361.42377292 -361.70506329\n",
      "  -360.94803265 -362.41593256 -361.07603127 -361.90263838 -361.19122371\n",
      "  -361.43759068 -361.15329592 -361.90838713 -361.26427072 -361.53239757\n",
      "  -361.27217086 -361.44488691 -361.26100205 -361.311458   -361.46791155\n",
      "  -361.57192239 -361.08817926 -361.70428948 -361.1864005  -361.55690933\n",
      "  -362.36821177 -360.79994297 -363.59960819 -361.05722515 -361.85112215\n",
      "  -360.8552144  -362.93471159 -361.20934549 -361.36923992 -361.76247555\n",
      "  -361.14297464 -361.69311049 -360.96732233 -362.30630321 -360.88700637\n",
      "  -362.74191692 -360.9024801  -362.23255993 -361.57697282 -360.89080835\n",
      "  -363.30172636 -361.23513041 -361.33685792 -361.60378146 -360.95764067\n",
      "  -362.58524351 -360.87914449 -362.55456856 -361.01851944 -361.70824643\n",
      "  -361.31467254 -361.48498766 -361.14538062 -361.57956538 -361.38686992\n",
      "  -361.37947502 -361.29814502 -361.27512947 -361.59603665 -362.10627916\n",
      "  -361.01506317 -361.8951208  -361.44437646 -361.73722031 -361.24929839\n",
      "  -361.7546776  -360.95766956 -362.22525238 -361.4032168  -360.99578979\n",
      "  -363.26947964 -361.17346116 -361.47409584 -361.30115849 -361.41687999\n",
      "  -361.29274345 -361.49981625 -361.13759662 -361.59183028 -361.37001923\n",
      "  -361.19456548 -361.73495672 -361.08780401 -361.89652303 -361.2320679\n",
      "  -361.67230968 -361.06592326 -361.69842026 -361.23714425 -361.7458503\n",
      "  -360.852342   -363.34941567 -361.26496068 -361.27426704 -361.41330678\n",
      "  -361.69669488 -360.96106491 -362.30446231 -361.22649864 -361.43596509\n",
      "  -361.32700178 -361.38259182 -361.34768223 -361.37980359 -361.33370763\n",
      "  -361.42016476 -361.25516209 -361.62380634 -360.97908668 -362.29985035\n",
      "  -361.18015597 -362.07103406 -361.27722396 -361.37578624 -361.4201332\n",
      "  -361.22163407 -361.42478821 -361.2514224  -361.55358877 -361.39468855\n",
      "  -361.36468118 -361.32453964 -361.46316834 -361.17861429 -361.49279361\n",
      "  -361.60848721 -361.03702214 -361.95585571 -361.20547781 -361.70835473\n",
      "  -361.27722811 -361.52876161 -361.2840855  -361.4042245  -361.73873444\n",
      "  -361.79571964 -361.11240033 -361.47741227 -361.27824497 -361.42692399]\n",
      " [-364.88195804 -362.11663885 -360.79371106 -361.55398091 -361.72044047\n",
      "  -361.14004203 -361.06452615 -361.72041341 -361.09281124 -362.40184138\n",
      "  -361.7030766  -360.90056458 -361.14017742 -362.36950294 -361.60374346\n",
      "  -361.94038465 -362.09115385 -362.01996557 -360.97973823 -360.97522397\n",
      "  -361.32905687 -361.87534715 -360.78692969 -361.57161843 -361.72620317\n",
      "  -361.11998327 -362.4505771  -361.55498662 -361.28749209 -360.80383719\n",
      "  -361.74693622 -362.32346487 -361.22223924 -360.94347721 -361.18450342\n",
      "  -360.86716867 -361.52846931 -361.60231296 -361.63887472 -361.64827264\n",
      "  -361.42802737 -362.04967787 -361.22990032 -362.14905263 -361.04270768\n",
      "  -361.00699239 -361.17014052 -360.83140468 -361.72942755 -362.23219328\n",
      "  -361.69709661 -361.65838454 -361.39435896 -360.7426372  -362.88109224\n",
      "  -362.31052721 -360.96125126 -361.0438791  -361.15193555 -362.12335755\n",
      "  -362.25150304 -361.67109909 -361.90609887 -362.52388871 -362.15781268\n",
      "  -361.15044519 -361.05626378 -360.93044915 -361.40428795 -361.76158153\n",
      "  -361.01576431 -361.26261097 -362.00371828 -361.38309259 -361.72874341\n",
      "  -361.10979498 -361.06434285 -360.95168495 -361.3192141  -361.74001126\n",
      "  -362.08785327 -360.96066062 -361.07830943 -361.06838346 -360.97674654\n",
      "  -361.23152018 -362.15832999 -361.02385275 -361.04247236 -362.45732965\n",
      "  -361.63954262 -361.04203755 -361.20894759 -362.10154963 -361.14454902\n",
      "  -360.85994801 -361.17359615 -360.99172142 -361.08633826 -361.01621185\n",
      "  -362.48454666 -361.51047262 -362.5681099  -361.58025455 -361.41153563\n",
      "  -361.85399299 -361.56266006 -361.14458528 -361.64940195 -362.39291845\n",
      "  -361.61279978 -362.25502688 -360.81359063 -361.08245309 -361.22889773\n",
      "  -361.74821562 -362.09293246 -360.95687258 -361.09736008 -361.02794343\n",
      "  -361.06003393 -361.0468332  -361.0478352  -361.05848198 -361.03077085\n",
      "  -361.09131576 -360.97010102 -361.22892881 -362.17789694 -360.9879646\n",
      "  -361.12928029 -360.92688334 -361.33883939 -361.75708174 -361.82636999\n",
      "  -361.58472739 -361.21212079 -360.87717723 -361.4476674  -361.77442552\n",
      "  -360.98175616 -361.35994628 -361.62570818 -362.49167399 -361.666538\n",
      "  -361.07308567 -361.16860015 -362.16886581 -361.0173139  -361.04297272\n",
      "  -361.09755474 -360.94414141 -361.31011759 -361.77002914 -361.96926841\n",
      "  -361.14466926 -362.11160058 -361.13026484 -362.27416737 -360.85607563\n",
      "  -361.50565503 -361.67107763 -361.31362965 -360.82180675 -361.19000652\n",
      "  -360.99700912 -362.40962835 -361.63254884 -362.11112219 -360.94236723\n",
      "  -361.11911813 -360.994886   -361.12589819 -362.23900302 -362.10620638\n",
      "  -360.91848623 -361.30251133 -362.07237301 -361.1915858  -361.9500756\n",
      "  -361.40349355 -361.81767148 -362.30768585 -361.33297361 -360.80457055\n",
      "  -361.68560125 -362.27894351 -361.95215455 -361.04696251 -360.86548075\n",
      "  -361.2418212  -360.86538491 -361.47359178 -361.61133503 -362.58337957\n",
      "  -361.55026547 -361.58021774 -361.80182889 -360.91058804 -361.61141465\n",
      "  -362.32767548 -361.13985673 -361.07113946 -360.90470348 -361.49047981\n",
      "  -361.60231967 -361.6283664  -361.6570151  -361.38677011 -362.11550669\n",
      "  -361.08109396 -360.96958801 -361.23727998 -362.15509067 -361.02884562\n",
      "  -361.03732214 -361.09538564 -362.28633873 -361.80462296 -361.49705105\n",
      "  -361.39491384 -361.77654786 -361.74249682 -361.63912102 -362.20051302\n",
      "  -360.83760277 -361.48854993 -361.76269949 -361.01120188 -362.63391719\n",
      "  -362.14999973 -361.19930948 -360.97817911 -361.09565579 -361.01272188\n",
      "  -361.10333547 -360.96111496 -361.24566073 -362.14795399 -361.03760623\n",
      "  -362.35062326 -361.9162295  -361.30067522 -361.72681046 -362.1568656\n",
      "  -360.87281569 -361.32961201 -362.09086544 -361.14715523 -360.84213469\n",
      "  -361.69271506 -362.34533162 -361.11352473 -361.11595123 -362.27395936\n",
      "  -360.85978747 -361.48351008 -361.71593029 -361.15185174 -361.00129868\n",
      "  -361.07561092 -361.03590801 -361.06054427 -361.03758995 -361.07119604\n",
      "  -361.0100857  -361.13548686 -360.89581241 -361.45489597 -361.70219535\n",
      "  -361.21590603 -361.72359698 -361.10862666 -361.04151342 -361.00958609\n",
      "  -361.16143284 -362.14445115 -362.16572196 -362.05043438 -361.02376164\n",
      "  -361.04782754 -361.07852588 -360.98270291 -361.20259677 -362.23347746\n",
      "  -360.89967051 -361.36943339 -361.71618414 -362.17245829 -360.88168531\n",
      "  -362.25069326 -360.94416502 -361.10891547 -361.04927182 -361.85388781\n",
      "  -360.84188419 -361.27202231 -362.14034932 -362.11189346 -362.10759992]]\n",
      "[[-360.54624298 -361.94347477 -364.59488744 -365.35650859 -361.07837215\n",
      "  -365.27484809 -363.94347127 -361.23302215 -365.24377226 -361.51619134\n",
      "  -361.2171339  -364.12901276 -365.07022809 -361.46636875 -361.31649044\n",
      "  -361.76181693 -360.87525952 -361.71775743 -364.67117917 -364.80592291\n",
      "  -365.09113411 -361.14619642 -364.12241058 -365.39149262 -361.0744572\n",
      "  -365.40622211 -361.51565006 -361.20031878 -365.26493805 -364.60345651\n",
      "  -365.55283845 -360.72268719 -365.59907042 -364.63319806 -364.85853127\n",
      "  -364.66187234 -365.25199502 -361.07801938 -365.76004356 -361.05879986\n",
      "  -365.66428882 -361.13292641 -365.28543983 -361.22815081 -364.92034977\n",
      "  -364.75927689 -364.79386247 -364.66700448 -365.50435055 -360.72562131\n",
      "  -366.10738215 -361.0490041  -365.42084673 -363.75351424 -362.17557231\n",
      "  -360.73283837 -364.5053768  -364.83393147 -364.96346377 -361.35307583\n",
      "  -361.56947634 -361.32956844 -361.51999971 -361.75033999 -360.78000008\n",
      "  -365.51827159 -364.67144241 -364.74649809 -365.15279844 -361.11497013\n",
      "  -365.17212082 -365.03559754 -361.17537615 -365.30861582 -361.11747511\n",
      "  -365.21026878 -364.70449896 -364.74281661 -365.08305252 -361.24951186\n",
      "  -361.54417756 -364.7357743  -364.83362568 -364.73454826 -364.74131863\n",
      "  -365.05698988 -361.23204357 -364.9135368  -364.92032532 -361.57059242\n",
      "  -361.18902362 -365.16799622 -364.99656165 -361.22563881 -364.94680621\n",
      "  -363.74505298 -364.98202792 -364.66724492 -364.80815911 -364.87604131\n",
      "  -361.58487508 -361.24439637 -362.02924177 -361.08999224 -365.63709446\n",
      "  -361.24077146 -361.38303226 -364.2963794  -361.27277319 -361.83281571\n",
      "  -361.23051407 -361.67474438 -363.70758234 -365.0104913  -364.95074388\n",
      "  -361.28278074 -361.52327143 -364.74566416 -364.83835559 -364.72102544\n",
      "  -364.77670677 -364.75008783 -364.7608541  -364.76001557 -364.75135874\n",
      "  -364.77426817 -364.72455332 -365.06100408 -361.23814916 -364.90350422\n",
      "  -364.80876306 -364.69756561 -365.11500647 -361.23368196 -361.63448119\n",
      "  -361.25058784 -365.17594175 -364.64336321 -365.22283821 -361.10431192\n",
      "  -365.16800111 -365.06549418 -361.18747211 -361.98063094 -361.10198383\n",
      "  -365.25289035 -364.9600168  -361.26193532 -364.88752937 -364.78122629\n",
      "  -364.76341422 -364.7193087  -365.08679659 -361.26195611 -361.48062392\n",
      "  -365.03640038 -361.25372845 -365.12819724 -361.30599351 -364.82797798\n",
      "  -365.2562125  -361.08689755 -365.33890739 -363.65821772 -365.03271708\n",
      "  -364.81479195 -361.5647227  -361.30622952 -361.55569638 -364.72528267\n",
      "  -364.85372608 -364.70485503 -364.98224763 -361.43297548 -361.33756281\n",
      "  -364.85092078 -365.13075184 -361.18155504 -365.19719365 -361.34116917\n",
      "  -361.29024064 -365.86694875 -360.71792379 -365.66098913 -364.58059764\n",
      "  -365.50544609 -360.77859355 -361.74738373 -364.67913031 -363.81123274\n",
      "  -364.98163968 -364.63012164 -365.22339923 -361.15410467 -362.06211837\n",
      "  -361.08485367 -365.77740818 -361.07195325 -365.16686791 -365.36861431\n",
      "  -360.73345299 -365.5396556  -364.67753003 -364.73377597 -365.19798489\n",
      "  -361.08535127 -365.74406175 -361.06086451 -365.63260198 -361.16208211\n",
      "  -364.99037944 -364.72788332 -365.06493531 -361.22883862 -364.91795318\n",
      "  -364.77046421 -364.94188334 -361.45432971 -361.39693159 -361.31263315\n",
      "  -365.43628615 -361.22054922 -361.59153054 -361.40882645 -361.52722518\n",
      "  -364.72396632 -365.27780392 -361.09371921 -365.29770162 -361.75237723\n",
      "  -360.77635672 -365.54864529 -364.64507964 -364.82170846 -364.72268774\n",
      "  -364.79026203 -364.71585802 -365.07513455 -361.22310765 -365.08551502\n",
      "  -361.53042202 -361.23436006 -365.24267652 -361.24949604 -361.574005\n",
      "  -364.71017352 -365.18500054 -361.17753512 -364.98512251 -364.67741082\n",
      "  -365.48338517 -360.72635392 -365.53663364 -364.91302747 -361.3154694\n",
      "  -364.82218023 -365.24683742 -361.09368228 -365.25510795 -364.6775373\n",
      "  -364.80011109 -364.73776144 -364.76999188 -364.74972924 -364.76856541\n",
      "  -364.74126525 -364.79219338 -364.69215381 -365.20103109 -361.10252151\n",
      "  -364.51739402 -361.17082502 -365.15552067 -364.7073669  -364.76323189\n",
      "  -364.99023031 -361.35907676 -361.54259793 -361.29308481 -364.90111795\n",
      "  -364.77611861 -364.75975476 -364.73415335 -365.0403272  -361.26340271\n",
      "  -364.86709518 -365.14477444 -361.22623401 -361.60373698 -363.94550282\n",
      "  -361.46770261 -364.73512778 -364.85757625 -363.97180014 -361.26506893\n",
      "  -364.03510909 -365.19279874 -361.31398005 -361.53686034 -361.3743101 ]\n",
      " [-363.57963374 -361.04711628 -361.8817551  -360.92012934 -362.34911626\n",
      "  -361.23902935 -361.38502518 -361.93664515 -361.29449352 -361.18911038\n",
      "  -361.99223922 -361.64947578 -361.24289977 -361.23683891 -361.92845281\n",
      "  -361.20661522 -362.59976265 -361.19580175 -361.47046332 -361.47272178\n",
      "  -361.06795204 -361.94180773 -361.94390574 -360.91049346 -362.35232496\n",
      "  -361.25943005 -361.17544879 -362.27985402 -361.09823883 -361.85173688\n",
      "  -360.82918238 -363.46702082 -361.15100585 -361.53435804 -361.2008788\n",
      "  -361.68739196 -360.93525663 -362.61879451 -360.87409335 -362.58580022\n",
      "  -360.99063587 -361.80957399 -361.14821321 -361.58395822 -361.36729972\n",
      "  -361.42419689 -361.21744374 -361.77341693 -360.83670674 -363.76046296\n",
      "  -360.84595229 -362.60562795 -361.01562996 -362.160244   -360.80974185\n",
      "  -363.35706001 -361.5090224  -361.36826537 -361.23245326 -361.44173874\n",
      "  -361.19999911 -361.82041912 -361.39748306 -361.01963285 -363.20384101\n",
      "  -361.22390023 -361.35682049 -361.55338383 -361.01262398 -362.16376707\n",
      "  -361.39921148 -361.12339834 -361.76577763 -361.02488129 -362.20747876\n",
      "  -361.2747429  -361.34484289 -361.51510294 -361.07574588 -361.88107309\n",
      "  -361.28319916 -361.49980405 -361.3225243  -361.33849634 -361.47260075\n",
      "  -361.15082297 -361.57322259 -361.39418635 -361.36762606 -361.13630109\n",
      "  -362.15414499 -361.36195945 -361.17338821 -361.61569423 -361.24092719\n",
      "  -361.78515474 -361.20906373 -361.45135001 -361.31313015 -361.40650158\n",
      "  -361.12008266 -362.24744189 -360.90023512 -362.6248892  -361.00169151\n",
      "  -361.77893446 -361.86953813 -361.26366666 -361.94931994 -361.0126244\n",
      "  -362.0946084  -361.13207776 -361.9187579  -361.31245506 -361.15551133\n",
      "  -361.81253356 -361.29730578 -361.50594293 -361.29858209 -361.39456208\n",
      "  -361.34814418 -361.36691953 -361.36517829 -361.35076527 -361.38942828\n",
      "  -361.30796058 -361.48425946 -361.15313863 -361.5540518  -361.44887105\n",
      "  -361.26172273 -361.56214032 -361.06006331 -361.89164471 -361.35270838\n",
      "  -362.09354484 -361.1667633  -361.66596125 -360.98328701 -362.17533715\n",
      "  -361.45140458 -361.04524916 -362.18190838 -360.9318204  -362.3700262\n",
      "  -361.31898924 -361.21478088 -361.52704363 -361.40452067 -361.3712153\n",
      "  -361.30060446 -361.52945005 -361.08286655 -361.8253463  -361.39620355\n",
      "  -361.23869096 -361.56970328 -361.25276184 -361.42377292 -361.70506329\n",
      "  -360.94803265 -362.41593256 -361.07603127 -361.90263838 -361.19122371\n",
      "  -361.43759068 -361.15329592 -361.90838713 -361.26427072 -361.53239757\n",
      "  -361.27217086 -361.44488691 -361.26100205 -361.311458   -361.46791155\n",
      "  -361.57192239 -361.08817926 -361.70428948 -361.1864005  -361.55690933\n",
      "  -362.36821177 -360.79994297 -363.59960819 -361.05722515 -361.85112215\n",
      "  -360.8552144  -362.93471159 -361.20934549 -361.36923992 -361.76247555\n",
      "  -361.14297464 -361.69311049 -360.96732233 -362.30630321 -360.88700637\n",
      "  -362.74191692 -360.9024801  -362.23255993 -361.57697282 -360.89080835\n",
      "  -363.30172636 -361.23513041 -361.33685792 -361.60378146 -360.95764067\n",
      "  -362.58524351 -360.87914449 -362.55456856 -361.01851944 -361.70824643\n",
      "  -361.31467254 -361.48498766 -361.14538062 -361.57956538 -361.38686992\n",
      "  -361.37947502 -361.29814502 -361.27512947 -361.59603665 -362.10627916\n",
      "  -361.01506317 -361.8951208  -361.44437646 -361.73722031 -361.24929839\n",
      "  -361.7546776  -360.95766956 -362.22525238 -361.4032168  -360.99578979\n",
      "  -363.26947964 -361.17346116 -361.47409584 -361.30115849 -361.41687999\n",
      "  -361.29274345 -361.49981625 -361.13759662 -361.59183028 -361.37001923\n",
      "  -361.19456548 -361.73495672 -361.08780401 -361.89652303 -361.2320679\n",
      "  -361.67230968 -361.06592326 -361.69842026 -361.23714425 -361.7458503\n",
      "  -360.852342   -363.34941567 -361.26496068 -361.27426704 -361.41330678\n",
      "  -361.69669488 -360.96106491 -362.30446231 -361.22649864 -361.43596509\n",
      "  -361.32700178 -361.38259182 -361.34768223 -361.37980359 -361.33370763\n",
      "  -361.42016476 -361.25516209 -361.62380634 -360.97908668 -362.29985035\n",
      "  -361.18015597 -362.07103406 -361.27722396 -361.37578624 -361.4201332\n",
      "  -361.22163407 -361.42478821 -361.2514224  -361.55358877 -361.39468855\n",
      "  -361.36468118 -361.32453964 -361.46316834 -361.17861429 -361.49279361\n",
      "  -361.60848721 -361.03702214 -361.95585571 -361.20547781 -361.70835473\n",
      "  -361.27722811 -361.52876161 -361.2840855  -361.4042245  -361.73873444\n",
      "  -361.79571964 -361.11240033 -361.47741227 -361.27824497 -361.42692399]\n",
      " [-364.88195804 -362.11663885 -360.79371106 -361.55398091 -361.72044047\n",
      "  -361.14004203 -361.06452615 -361.72041341 -361.09281124 -362.40184138\n",
      "  -361.7030766  -360.90056458 -361.14017742 -362.36950294 -361.60374346\n",
      "  -361.94038465 -362.09115385 -362.01996557 -360.97973823 -360.97522397\n",
      "  -361.32905687 -361.87534715 -360.78692969 -361.57161843 -361.72620317\n",
      "  -361.11998327 -362.4505771  -361.55498662 -361.28749209 -360.80383719\n",
      "  -361.74693622 -362.32346487 -361.22223924 -360.94347721 -361.18450342\n",
      "  -360.86716867 -361.52846931 -361.60231296 -361.63887472 -361.64827264\n",
      "  -361.42802737 -362.04967787 -361.22990032 -362.14905263 -361.04270768\n",
      "  -361.00699239 -361.17014052 -360.83140468 -361.72942755 -362.23219328\n",
      "  -361.69709661 -361.65838454 -361.39435896 -360.7426372  -362.88109224\n",
      "  -362.31052721 -360.96125126 -361.0438791  -361.15193555 -362.12335755\n",
      "  -362.25150304 -361.67109909 -361.90609887 -362.52388871 -362.15781268\n",
      "  -361.15044519 -361.05626378 -360.93044915 -361.40428795 -361.76158153\n",
      "  -361.01576431 -361.26261097 -362.00371828 -361.38309259 -361.72874341\n",
      "  -361.10979498 -361.06434285 -360.95168495 -361.3192141  -361.74001126\n",
      "  -362.08785327 -360.96066062 -361.07830943 -361.06838346 -360.97674654\n",
      "  -361.23152018 -362.15832999 -361.02385275 -361.04247236 -362.45732965\n",
      "  -361.63954262 -361.04203755 -361.20894759 -362.10154963 -361.14454902\n",
      "  -360.85994801 -361.17359615 -360.99172142 -361.08633826 -361.01621185\n",
      "  -362.48454666 -361.51047262 -362.5681099  -361.58025455 -361.41153563\n",
      "  -361.85399299 -361.56266006 -361.14458528 -361.64940195 -362.39291845\n",
      "  -361.61279978 -362.25502688 -360.81359063 -361.08245309 -361.22889773\n",
      "  -361.74821562 -362.09293246 -360.95687258 -361.09736008 -361.02794343\n",
      "  -361.06003393 -361.0468332  -361.0478352  -361.05848198 -361.03077085\n",
      "  -361.09131576 -360.97010102 -361.22892881 -362.17789694 -360.9879646\n",
      "  -361.12928029 -360.92688334 -361.33883939 -361.75708174 -361.82636999\n",
      "  -361.58472739 -361.21212079 -360.87717723 -361.4476674  -361.77442552\n",
      "  -360.98175616 -361.35994628 -361.62570818 -362.49167399 -361.666538\n",
      "  -361.07308567 -361.16860015 -362.16886581 -361.0173139  -361.04297272\n",
      "  -361.09755474 -360.94414141 -361.31011759 -361.77002914 -361.96926841\n",
      "  -361.14466926 -362.11160058 -361.13026484 -362.27416737 -360.85607563\n",
      "  -361.50565503 -361.67107763 -361.31362965 -360.82180675 -361.19000652\n",
      "  -360.99700912 -362.40962835 -361.63254884 -362.11112219 -360.94236723\n",
      "  -361.11911813 -360.994886   -361.12589819 -362.23900302 -362.10620638\n",
      "  -360.91848623 -361.30251133 -362.07237301 -361.1915858  -361.9500756\n",
      "  -361.40349355 -361.81767148 -362.30768585 -361.33297361 -360.80457055\n",
      "  -361.68560125 -362.27894351 -361.95215455 -361.04696251 -360.86548075\n",
      "  -361.2418212  -360.86538491 -361.47359178 -361.61133503 -362.58337957\n",
      "  -361.55026547 -361.58021774 -361.80182889 -360.91058804 -361.61141465\n",
      "  -362.32767548 -361.13985673 -361.07113946 -360.90470348 -361.49047981\n",
      "  -361.60231967 -361.6283664  -361.6570151  -361.38677011 -362.11550669\n",
      "  -361.08109396 -360.96958801 -361.23727998 -362.15509067 -361.02884562\n",
      "  -361.03732214 -361.09538564 -362.28633873 -361.80462296 -361.49705105\n",
      "  -361.39491384 -361.77654786 -361.74249682 -361.63912102 -362.20051302\n",
      "  -360.83760277 -361.48854993 -361.76269949 -361.01120188 -362.63391719\n",
      "  -362.14999973 -361.19930948 -360.97817911 -361.09565579 -361.01272188\n",
      "  -361.10333547 -360.96111496 -361.24566073 -362.14795399 -361.03760623\n",
      "  -362.35062326 -361.9162295  -361.30067522 -361.72681046 -362.1568656\n",
      "  -360.87281569 -361.32961201 -362.09086544 -361.14715523 -360.84213469\n",
      "  -361.69271506 -362.34533162 -361.11352473 -361.11595123 -362.27395936\n",
      "  -360.85978747 -361.48351008 -361.71593029 -361.15185174 -361.00129868\n",
      "  -361.07561092 -361.03590801 -361.06054427 -361.03758995 -361.07119604\n",
      "  -361.0100857  -361.13548686 -360.89581241 -361.45489597 -361.70219535\n",
      "  -361.21590603 -361.72359698 -361.10862666 -361.04151342 -361.00958609\n",
      "  -361.16143284 -362.14445115 -362.16572196 -362.05043438 -361.02376164\n",
      "  -361.04782754 -361.07852588 -360.98270291 -361.20259677 -362.23347746\n",
      "  -360.89967051 -361.36943339 -361.71618414 -362.17245829 -360.88168531\n",
      "  -362.25069326 -360.94416502 -361.10891547 -361.04927182 -361.85388781\n",
      "  -360.84188419 -361.27202231 -362.14034932 -362.11189346 -362.10759992]]\n"
     ]
    }
   ],
   "source": [
    "print(log_gamma)\n",
    "\n",
    "print(log_gamma_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating parameters of an homogeneous Markov chain\n",
    "$\\newcommand{\\ind}[1]{\\left[{#1}\\right]}$\n",
    "\n",
    "We have a Markov chain with transition probabilities $p(x_t = i| x_{t-1} = j) =  A_{i,j}$\n",
    "and initial state $p(x_1) = \\pi_i$.\n",
    "\n",
    "The distributions are\n",
    "\\begin{eqnarray}\n",
    "p(x_1 |\\pi)& = &\\prod_{s=1}^{S} \\pi_s^{\\ind{s = x_1}} \\\\\n",
    "p(x_t | x_{t-1}, A) &=& \\prod_{j=1}^{S} \\prod_{s=1}^{S}  A_{s,j}^{{\\ind{s = x_t}}\\ind{j = x_{t-1}}} \\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "The loglikelihood is\n",
    "\\begin{eqnarray}\n",
    "{\\cal L}(\\pi, A) & = & \\log \\left( p(x_1 | \\pi) \\prod_{t=2}^T p(x_t | x_{t-1}, A) \\right) \\\\\n",
    "& = & \\sum_{s=1}^{S} {\\ind{s = x_1}} \\log \\pi_s + \\sum_{t=2}^T \\sum_{j=1}^{S}\\sum_{s=1}^{S} {{\\ind{s = x_t}}\\ind{j = x_{t-1}}} \\log A_{s,j}\n",
    "\\end{eqnarray}\n",
    "\n",
    "We have the constraints $\\sum_s \\pi_s = 1$ and $\\sum_i A_{i,j} = 1$ for all $j=1 \\dots S$ so we have $S+1$ constraints. We write the Lagrangian\n",
    "\\begin{eqnarray}\n",
    "\\Lambda(\\pi, A, \\lambda^\\pi, \\lambda^A) & = & \\sum_{s=1}^{S} {\\ind{s = x_1}} \\log \\pi_s + \\sum_{t=2}^T \\sum_{j=1}^{S} \\sum_{s=1}^{S} {{\\ind{s = x_t}}\\ind{j = x_{t-1}}} \\log A_{s,j} \\\\\n",
    "& & + \\lambda^\\pi \\left( 1 - \\sum_s \\pi_s \\right) + \\sum_j \\lambda^A_j \\left( 1 - \\sum_s A_{s,j} \\right)\n",
    "\\end{eqnarray}\n",
    "\n",
    "To find $\\pi$ and $A$ we take the derivative of the Lagrangian\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial \\Lambda(\\pi, A,\\lambda^\\pi, \\lambda^A)}{\\partial \\pi_i} & = & {\\ind{i = x_1}} \\frac{1}{\\pi_i} - \\lambda^\\pi = 0\\\\\n",
    "\\frac{\\partial \\Lambda(\\pi, A, \\lambda^\\pi, \\lambda^A)}{\\partial A_{i,j}} & = & \\sum_{t=2}^T {{\\ind{i = x_t}}\\ind{j = x_{t-1}}} \\frac{1}{A_{i,j}} - \\lambda^A_j = 0\n",
    "\\end{eqnarray}\n",
    "\n",
    "Substitute the constraints $\\sum_s \\pi_s = 1$ and $\\sum_s A_{s,j} = 1, \\; j=1\\dots S$.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\pi_i & = & {\\ind{i = x_1}} \\frac{1}{\\lambda^\\pi} \\\\\n",
    "\\sum_i \\pi_i & = & \\frac{1}{\\lambda^\\pi} \\sum_i {\\ind{i = x_1}} = 1\\\\\n",
    "\\lambda^\\pi & = & 1\\\\\n",
    "\\pi_i & = & {\\ind{i = x_1}}\n",
    "\\end{eqnarray}\n",
    "As we have effectively only a single observation for $x_1$, we have a crisp estimate.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "A_{i,j} & = & \\sum_{t=2}^T {{\\ind{i = x_t}}\\ind{j = x_{t-1}}} \\frac{1}{\\lambda^A_j} \\\\\n",
    "\\sum_i A_{i,j} & = & \\sum_i \\sum_{t=2}^T {{\\ind{i = x_t}}\\ind{j = x_{t-1}}} \\frac{1}{\\lambda^A_j} = 1 \\\\\n",
    "\\lambda^A_j & = & \\sum_{t=2}^T \\sum_i  {{\\ind{i = x_t}}\\ind{j = x_{t-1}}} \\\\\n",
    "A_{i,j} & = & \\frac{\\sum_{t=2}^T {{\\ind{i = x_t}}\\ind{j = x_{t-1}}}}{\\sum_{t=2}^T \\sum_i  {{\\ind{i = x_t}}\\ind{j = x_{t-1}}}}\\\\\n",
    "& = & \\frac{\\sum_{t=2}^T {{\\ind{i = x_t}}\\ind{j = x_{t-1}}}}{\\sum_{t=2}^T \\ind{j = x_{t-1}}}\n",
    "\\end{eqnarray}\n",
    "The result is intuitive. The denominator counts the number of times the chain visited state $j$ in the previous state. The numerator counts the number of times we visit $i$ given we were at $j$ the previous time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating parameters of an homogeneous Markov chain when several sequences are observed\n",
    "\n",
    "Suppose we have observed several sequences\n",
    "\\begin{eqnarray}\n",
    "X = \\{x_1^{(n)}, x_2^{(n)}, \\dots, x_{T_n}^{(n)}   \\}\n",
    "\\end{eqnarray}\n",
    "for $n = 1\\dots N$. Here $T_n$ is the length of the $n$'th sequence.\n",
    "\n",
    "The notation becomes slightly more complicated but conceptully the derivation is similar.\n",
    "\n",
    "The joint probability of all sequences is\n",
    "\\begin{eqnarray}\n",
    "p(X | \\pi, A) & = & \\prod_n \\left( p(x_1^{(n)}) \\prod_{t=2}^{T_n} p(x_t^{(n)}| x_{t-1}^{(n)} ) \\right)\n",
    "\\end{eqnarray}\n",
    "The loglikelihood is\n",
    "\\begin{eqnarray}\n",
    "{\\cal L}(\\pi, A) & = & \\sum_n \\left( \\log p(x_1^{(n)}) + \\sum_{t=2}^{T_n} \\log p(x_t^{(n)}| x_{t-1}^{(n)} ) \\right) \\\\\n",
    "& = & \\sum_n \\left( \\sum_{s=1}^{S} {\\ind{s = x_1^{(n)}}} \\log \\pi_s + \\sum_{t=2}^{T_n}\\sum_{j=1}^{S}\n",
    "\\sum_{s=1}^{S} {\\ind{s = x_t^{(n)}}}\\ind{j = x_{t-1}^{(n)}} \\log A_{s,j} \\right) \\\\\n",
    "& = & \\sum_{s=1}^{S} \\sum_n  {\\ind{s = x_1^{(n)}}} \\log \\pi_s + \\sum_n \\sum_{t=2}^{T_n}\n",
    "\\sum_{j=1}^{S} \\sum_{s=1}^{S}   {\\ind{s = x_t^{(n)}}}\\ind{j = x_{t-1}^{(n)}} \\log A_{s,j}\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "We write the Lagrangian\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\Lambda(\\pi, A, \\lambda^\\pi, \\lambda^A)\n",
    "& = & \\sum_{s=1}^{S} \\sum_n  {\\ind{s = x_1^{(n)}}} \\log \\pi_s + \\sum_n  \\sum_{t=2}^{T_n} \\sum_{j=1}^{S}\n",
    "\\sum_{s=1}^{S}  {\\ind{s = x_t^{(n)}}}\\ind{j = x_{t-1}^{(n)}} \\log A_{s,j} \\\\\n",
    "& & + \\lambda^\\pi \\left( 1 - \\sum_s \\pi_s \\right) + \\sum_j \\lambda^A_j \\left( 1 - \\sum_s A_{s,j} \\right)\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find $\\pi$ and $A$ we take the derivative of the Lagrangian\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial \\Lambda(\\pi, A,\\lambda^\\pi, \\lambda^A)}{\\partial \\pi_i} & = & \\sum_n {\\ind{i = x_1^{(n)}}} \\frac{1}{\\pi_i} - \\lambda^\\pi = 0\\\\\n",
    "\\frac{\\partial \\Lambda(\\pi, A, \\lambda^\\pi, \\lambda^A)}{\\partial A_{i,j}} & = &  \\sum_n \\sum_{t=2}^{T_n} {{\\ind{i = x_t^{(n)}}}\\ind{j = x_{t-1}^{(n)}}} \\frac{1}{A_{i,j}} - \\lambda^A_j = 0\n",
    "\\end{eqnarray}\n",
    "\n",
    "#### Prior\n",
    "\\begin{eqnarray}\n",
    "\\pi_i & = & \\sum_n {\\ind{i = x_1^{(n)}}} \\frac{1}{\\lambda^\\pi}\\\\\n",
    "\\sum \\pi_i & = & \\frac{1}{\\lambda^\\pi} \\sum_i \\sum_n {\\ind{i = x_1^{(n)}}} = 1 \\\\\n",
    "\\lambda^\\pi & = & \\sum_i \\sum_n {\\ind{i = x_1^{(n)}}} = N \\\\\n",
    "\\pi_i & = & \\frac{1}{N} \\sum_n {\\ind{i = x_1^{(n)}}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "#### Transition Matrix\n",
    "\n",
    "\\begin{eqnarray}\n",
    "A_{i,j} & = & \\sum_n \\sum_{t=2}^{T_n}  {{\\ind{i = x_t^{(n)}}}\\ind{j = x_{t-1}^{(n)}}} \\frac{1}{\\lambda^A_j} \\\\\n",
    "\\sum_i A_{i,j} & = & \\sum_i \\sum_n \\sum_{t=2}^{T_n} {{\\ind{i = x_t^{(n)}}}\\ind{j = x_{t-1}^{(n)}}} \\frac{1}{\\lambda^A_j} = 1 \\\\\n",
    "\\lambda^A_j & = & \\sum_i \\sum_n  \\sum_{t=2}^{T_n} {{\\ind{i = x_t^{(n)}}}\\ind{j = x_{t-1}^{(n)}}} \\\\\n",
    "& = &  \\sum_n \\sum_{t=2}^{T_n}  \\ind{j = x_{t-1}^{(n)}} \\\\\n",
    "A_{i,j} & = &  \\frac{\\sum_n \\sum_{t=2}^{T_n}  {{\\ind{i = x_t^{(n)}}}\\ind{j = x_{t-1}^{(n)}}}}{\\sum_n \\sum_{t=2}^{T_n}  {\\ind{j = x_{t-1}^{(n)}}}}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The EM Algorithm\n",
    "\n",
    "$\\newcommand{\\E}[1]{\\left\\langle#1\\right\\rangle}$\n",
    "\n",
    "The EM algorithm is a standart approach for ML estimation, when we have hidden variables.\n",
    "The canonical model is $p(y, x| \\theta)$ where we observe only $y$.\n",
    "\n",
    "The observed data loglikelihood is\n",
    "\\begin{eqnarray}\n",
    "{\\cal L}(\\theta) & = & \\log p(y| \\theta) = \\log \\sum_x p(y, x| \\theta)\n",
    "\\end{eqnarray}\n",
    "\n",
    "The key to the EM algorithm is the Jensen's inequality, that states for a concave function $f$ we have for $0 \\leq \\lambda \\leq 1$\n",
    "\n",
    "\n",
    "\\begin{eqnarray}\n",
    "f(\\lambda x_1 + (1 - \\lambda) x_2) \\geq \\lambda f( x_1) + (1 - \\lambda) f(x_2)\n",
    "\\end{eqnarray}\n",
    "\n",
    "In words the value of a function evaluated at the convex combination (lhs) is always equal and larger then the convex combination of the function values. As mathematical expectation\n",
    "\\begin{eqnarray}\n",
    "\\E{f(x)} & = & \\sum_x p(x) f(x) \\\\\n",
    "\\sum_x p(x) & = & 1\n",
    "\\end{eqnarray}\n",
    "\n",
    "As $\\log(x)$  is a concave function, we have\n",
    "\n",
    "\\begin{eqnarray}\n",
    " f(\\E{x}) & \\geq & \\E{f(x)}\n",
    "\\end{eqnarray}\n",
    "\n",
    "The key idea of the EM algorithm is to lower bound the observed data likelihood an maximize the bound with respect to the parameters. We take any distribution $q(x)$\n",
    "\\begin{eqnarray}\n",
    "{\\cal L}(\\theta) & = & \\log \\sum_x p(y, x| \\theta) \\\\\n",
    "& = & \\log \\sum_x p(y, x| \\theta) \\frac{q(x)}{q(x)} \\\\\n",
    "& = & \\log  \\E{\\frac{p(y, x| \\theta)}{q(x)}}_{q(x)}\\\\\n",
    "& \\geq & \\E{\\log {p(y, x| \\theta)}}_{q(x)} -\\E{\\log{q(x)} }_{q(x)}\\\\\n",
    "\\end{eqnarray}\n",
    "For _any_ $q(x)$, we have a lower bound. The natural strategy here is to choose the $q(x)$ that will maximise the lower bound. This is an optimisation problem. To make the notation more familiar, we let $q(x = i) = q_i$. Then, we arrive at the Lagrangian\n",
    "\\begin{eqnarray}\n",
    "\\Lambda(q, \\lambda) & = & \\sum_i q_i \\log p(y, x=i| \\theta) - \\sum_i q_i \\log q_i \\\\\n",
    "& & + \\lambda (1 - \\sum_i q_i)\n",
    "\\end{eqnarray}\n",
    "We take the derivative with respect to $q_i$\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial \\Lambda(q, \\lambda)}{\\partial q_k} & = & \\log p(y, x=k| \\theta) - (\\log q_k + 1) - \\lambda = 0\\\\\n",
    "\\log q_k  & = & \\log p(y, x=k| \\theta) -1 - \\lambda \\\\\n",
    "q_k  & = & p(y, x=k| \\theta) \\exp(-1 - \\lambda) \\\\\n",
    "\\sum_k q_k & = & \\exp(-1 - \\lambda) \\sum_k p(y, x=k| \\theta) = 1\\\\\n",
    "\\exp(1 + \\lambda) & = & p(y | \\theta) \\\\\n",
    "\\exp(-1 - \\lambda) & = & 1/p(y | \\theta) \\\\\n",
    "\\end{eqnarray}\n",
    "hence we have\n",
    "\\begin{eqnarray}\n",
    "q_k  & = & p(y, x=k| \\theta)/p(y | \\theta) = p(x=k| y \\theta)\n",
    "\\end{eqnarray}\n",
    "This result shows that the best we can do is to choose the posterior distribution\n",
    "\\begin{eqnarray}\n",
    "q(x) & = & p(x| y, \\theta)\n",
    "\\end{eqnarray}\n",
    "The EM algorithm is an iterative algorithm that exploits this bound result. Given a particular parameter setting $\\theta^{(\\tau)}$ at iteration $\\tau$, we can compute a lower bound of the true likelihood function.\n",
    "\\begin{eqnarray}\n",
    "{\\cal L}(\\theta) & \\geq & \\E{\\log {p(y, x| \\theta)}}_{p(x| y, \\theta^{(\\tau)})} -\\E{\\log p(x| y, \\theta^{(\\tau)}) }_{p(x| y, \\theta^{(\\tau)})}\\\\\n",
    "& \\equiv & {\\cal F}[\\theta; \\theta^{(\\tau)}] +  H[p(x| y, \\theta^{(\\tau)})]\n",
    "\\end{eqnarray}\n",
    "We need to show that\n",
    "\\begin{eqnarray}\n",
    "{\\cal L}(\\theta^{(\\tau)}) & = & \\E{\\log {p(y, x| \\theta)}}_{p(x| y, \\theta^{(\\tau)})} -\\E{\\log p(x| y, \\theta^{(\\tau)}) }_{p(x| y, \\theta^{(\\tau)})}\\\\\n",
    "& = & {\\cal F}[\\theta^{(\\tau)}; \\theta^{(\\tau)}] +  H[p(x| y, \\theta^{(\\tau)})]\n",
    "\\end{eqnarray}\n",
    "In other words, the bound is tight at $\\theta^{(\\tau)}$, hence maximizing the bound guarantees maximization of the true loglikelihoood.\n",
    "\n",
    "In most cases, where the EM algorithm can be applied, the joint distribution is from an {\\it exponential family}, i.e., it has the generic algebraic form\n",
    "\\begin{eqnarray}\n",
    "p(y, x| \\theta) & = & b(y, x)\\exp( \\sum_l \\phi_l(y, x) \\psi(\\theta_l) - A(\\theta)   )\n",
    "\\end{eqnarray}\n",
    "where $\\phi_l$ are the sufficient statistics and $\\psi(\\theta_l)$ are the {\\it canonical} parameters. The canonical parameters are in one to one relation with a conventional parametrisation. We will give several explicit examples when we cover the HMM's of the next section.\n",
    "\n",
    "In the case when the complete data likelihood is an exponential family, the computation of the bound requires the expectation\n",
    "\\begin{eqnarray}\n",
    "\\E{\\log p(y, x| \\theta)} & = & \\E{\\log b(x, y)} + \\sum_l \\E{\\phi_l(y, x)} \\psi(\\theta_l) - A(\\theta)\n",
    "\\end{eqnarray}\n",
    "where the expectation is taken with respect to the posterior $p(x|y, \\theta^{(\\tau)})$. In other words, we need to compute expectations of form $\\E{\\phi_l(y, x)}$. Once these are available, we have effectively an expression for ${\\cal F}(\\theta; \\theta^{(\\tau)})$. By maximisation of ${\\cal F}$ with respect to $\\theta$,  and arrive at $\\theta^{(\\tau + 1)}$ and complete the iteration.\n",
    "\n",
    "In a rather abstract sense, the EM algorithm proceeds as follows:\n",
    "\n",
    "##### The Expectation/Maximization (EM) algorithm.\n",
    "\n",
    "\\begin{algorithmic}\n",
    "\\STATE Initialise $\\theta^{(0)}$\n",
    "\\FOR{  $\\text{epoch} = 1 \\dots $  MAXITER}\n",
    "\\STATE E-step. Compute the sufficient statistics of the complete data likelihood\n",
    "\\STATE M-step. Maximize with respect to the parameters $\\theta$ to find $\\theta^{(\\tau + 1)}$\n",
    "\\ENDFOR\n",
    "\\end{algorithmic}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning HMM parameters by EM\n",
    "\n",
    "Suppose we have observed several sequences\n",
    "\\begin{eqnarray}\n",
    "Y = \\{y_1^{(n)}, y_2^{(n)}, \\dots, y_{T_n}^{(n)}   \\}\n",
    "\\end{eqnarray}\n",
    "for $n = 1\\dots N$. Here $T_n$ is the length of the $n$'th sequence.\n",
    "Let $Y \\in \\{1,\\dots, R\\}$ and $X \\in \\{1,\\dots, S \\}$.\n",
    "\n",
    "The discrete observation, discrete state space HMM has the following factors:\n",
    "\\begin{eqnarray}\n",
    "p(x_1 = i) & = & \\pi_i \\\\\n",
    "p(y_k = r| x_k = i) & = & B_{r,i} \\\\\n",
    "p(x_k = i| x_{k-1} = j) & = & A_{i,j} \n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "The joint probability of all observed sequences and corresponding hidden sequences are\n",
    "\\begin{eqnarray}\n",
    "p(Y, X | \\pi, A, B) & = & \\prod_n \\left( p(x_1^{(n)}) p(y_1^{(n)} | x_1^{(n)})  \\prod_{t=2}^{T_n} p(y_t^{(n)} | x_t^{(n)}) p(x_t^{(n)}| x_{t-1}^{(n)} ) \\right)\n",
    "\\end{eqnarray}\n",
    "The expected complete data loglikelihood is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "{\\cal L}(\\pi, A, B) & = & \\E{\\sum_n \\left( \\log p(x_1^{(n)}) + \\sum_{t=1}^{T_n} \\log p(x_t^{(n)}| x_{t-1}^{(n)} ) + \\sum_{t=2}^{T_n} \\log p(y_t^{(n)} | x_t^{(n)}) \\right)} \\\\\n",
    "& = & \\E{\\sum_n \\left( \\sum_{s=1}^{S} {\\ind{s = x_1^{(n)}}} \\log \\pi_s   + \\log \\pi_s \\sum_{t=2}^{T_n}\\sum_{j=1}^{S}\n",
    "\\sum_{s=1}^{S} {\\ind{s = x_t^{(n)}}}\\ind{j = x_{t-1}^{(n)}} \\log A_{s,j} + \\sum_{t=1}^{T_n}\\sum_{r=1}^{R}\n",
    "\\sum_{i=1}^{S} {\\ind{r = y_t^{(n)}}}\\ind{i = x_{t}^{(n)}} \\log B_{r,i}\\right)} \\\\\n",
    "& = & \\sum_n \\sum_{s=1}^{S}   \\E{{\\ind{s = x_1^{(n)}}}} \\log \\pi_s  + \\sum_n \\sum_{t=2}^{T_n}\n",
    "\\sum_{j=1}^{S} \\sum_{s=1}^{S}   \\E{{\\ind{s = x_t^{(n)}}}\\ind{j = x_{t-1}^{(n)}}} \\log A_{s,j} + \\sum_n \\sum_{t=1}^{T_n}\\sum_{r=1}^{R}\n",
    "\\sum_{i=1}^{S} \\E{{\\ind{r = y_t^{(n)}}}\\ind{i = x_{t}^{(n)}}} \\log B_{r,i} \\\\\n",
    "& = & \\sum_{s=1}^{S} \\underbrace{\\left( \\sum_n \\E{ {\\ind{s = x_1^{(n)}}}} \\right)}_{\\equiv C_{\\pi}} \\log \\pi_s  + \n",
    "\\sum_{j=1}^{S} \\sum_{s=1}^{S} \\underbrace{\\left(  \\sum_n \\sum_{t=2}^{T_n} \\E{{\\ind{s = x_t^{(n)}}}\\ind{j = x_{t-1}^{(n)}}} \\right)}_{\\equiv C_{A}} \\log A_{s,j} + \\sum_{r=1}^{R}\n",
    "\\sum_{i=1}^{S} \\underbrace{\\left(  \\sum_n \\sum_{t=1}^{T_n} \\E{{\\ind{r = y_t^{(n)}}}\\ind{i = x_{t}^{(n)}}} \\right)}_{\\equiv C_{B}} \\log B_{r,i} \n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The M-Step\n",
    "We write the Lagrangian to ensure that the columns of $A$ and $B$ are positive and normalized\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\Lambda(\\pi, A, \\lambda^\\pi, \\lambda^A, \\lambda^B)\n",
    "& = & \\sum_{s=1}^{S} C_{\\pi}(s) \\log \\pi_s + \\sum_{j=1}^{S}\n",
    "\\sum_{s=1}^{S}  C_{A}(s,j) \\log A_{s,j} + \\sum_{r=1}^{R}\n",
    "\\sum_{i=1}^{S} C_{B}(r,i) \\log B_{r,i} \\\\\n",
    "& & + \\lambda^\\pi \\left( 1 - \\sum_s \\pi_s \\right) + \\sum_j \\lambda^A_j \\left( 1 - \\sum_s A_{s,j} \\right)\n",
    "+ \\sum_i \\lambda^B_i \\left( 1 - \\sum_r B_{r,i} \\right)\n",
    "\\end{eqnarray}\n",
    "\n",
    "To find $\\pi$, $A$ and $B$ we take the derivative of the Lagrangian\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial \\Lambda(\\pi, A,\\lambda^\\pi, \\lambda^A, \\lambda^B)}{\\partial \\pi_i} & = & C_{\\pi}(i) \\frac{1}{\\pi_i} - \\lambda^\\pi = 0\\\\\n",
    "\\frac{\\partial \\Lambda(\\pi, A, \\lambda^\\pi, \\lambda^A, \\lambda^B)}{\\partial A_{i,j}} & = &  C_{A}(i,j) \\frac{1}{A_{i,j}} - \\lambda^A_j = 0 \\\\\n",
    "\\frac{\\partial \\Lambda(\\pi, B, \\lambda^\\pi, \\lambda^A, \\lambda^B)}{\\partial B_{k,i}} & = &  C_{B}(k,i) \\frac{1}{B_{k,i}} - \\lambda^B_i = 0 \\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "#### Prior\n",
    "We set the derivative to zero and solve for $\\pi$\n",
    "\\begin{eqnarray}\n",
    "\\pi_i & = & C_{\\pi}(i) \\frac{1}{\\lambda^\\pi}\n",
    "\\end{eqnarray}\n",
    "As we have the normalization constraint for $\\pi$, we also have the following equality from which we can solve for the Lagrange multiplier:\n",
    "\\begin{eqnarray}\n",
    "\\sum_i \\pi_i & = & \\frac{1}{\\lambda^\\pi} \\sum_i C_{\\pi}(i) = 1 \\\\\n",
    "\\lambda^\\pi & = & \\sum_i  C_{\\pi}(i)  = N \n",
    "\\end{eqnarray}\n",
    "Substituting, we obtain the intuitive answer:\n",
    "\\begin{eqnarray}\n",
    "\\pi_i & = & \\frac{1}{N} C_{\\pi}(i)\n",
    "\\end{eqnarray}\n",
    "\n",
    "#### Transition Matrix\n",
    "\n",
    "\\begin{eqnarray}\n",
    "A_{i,j} & = & C_A(i,j) \\frac{1}{\\lambda^A_j} \\\\\n",
    "\\sum_i A_{i,j} & = & \\sum_i C_A(i,j) \\frac{1}{\\lambda^A_j} = 1 \\\\\n",
    "\\lambda^A_j & = & \\sum_i C_A(i,j) \\\\\n",
    "A_{i,j} & = &  \\frac{C_A(i,j)}{\\sum_i C_A(i,j)}\n",
    "\\end{eqnarray}\n",
    "\n",
    "#### Observation Matrix\n",
    "\\begin{eqnarray}\n",
    "B_{k,i} & = & C_B(k,i) \\frac{1}{\\lambda^B_i} \\\\\n",
    "\\sum_k B_{k,i} & = & \\sum_k C_B(k,i) \\frac{1}{\\lambda^B_i} = 1 \\\\\n",
    "\\lambda^B_i & = & \\sum_k C_B(k,i) \\\\\n",
    "B_{k,i} & = &  \\frac{C_B(k,i)}{\\sum_k C_B(k,i)}\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "S = 3\n",
    "R = 5\n",
    "A = np.random.dirichlet(0.7*np.ones(S),S).T\n",
    "B = np.random.dirichlet(0.7*np.ones(R),S).T\n",
    "p = np.random.dirichlet(0.7*np.ones(S)).T\n",
    "\n",
    "y = np.array([0, 1, 3, 2, 4])\n",
    "\n",
    "hm = HMM(p, A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward smoothers\n",
    "\n",
    "The EM algorithm requires obtaining the sufficient statistics of an HMM.  \n",
    "\n",
    "The key observation is that the sufficient statistics are additive:\n",
    "\\begin{eqnarray}\n",
    "C_t & = & \\int \\left(\\sum_{k=2}^t s_k(x_{k-1}, x_{k}) \\right) p(x_{1:t}|y_{1:t}) dx_{1:t}\n",
    "\\end{eqnarray}\n",
    "\n",
    "The derivation depends on the following decomposition. By chain rule, we write\n",
    "\\begin{eqnarray}\n",
    "p(x_{1:t}|y_{1:t}) & = & p(x_{1}|x_{2:t}, y_{1:t}) \\cdots p(x_{t-2}|x_{t-1:t}, y_{1:t}) p(x_{t-1}|x_t, y_{1:t}) p(x_{t}|y_{1:t}) \n",
    "\\end{eqnarray}\n",
    "The key observation is that this expression admits computation in the forward direction. By conditional independence\n",
    "\\begin{eqnarray}\n",
    "p(x_{1:t}|y_{1:t}) & = & p(x_{1}|x_{2}, y_{1}) \\cdots p(x_{t-2}|x_{t-1}, y_{1:t-2}) p(x_{t-1}|x_t, y_{1:t-1}) p(x_{t}|y_{1:t}) \n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "\n",
    "We will use this observation as the basis of a forward recursion. First we decompose the posterior \n",
    "as a product of the filtering density at time $t$ and a conditional quantity familiar from the correction smoother \n",
    "\\begin{eqnarray}\n",
    "C_t & = & \\int \\int \\left(\\sum_{k=2}^t s_k(x_{k-1}, x_{k})\\right) p(x_{1:t-1}|y_{1:t},x_t) p(x_{t}|y_{1:t}) dx_{1:t-1} dx_t \\\\\n",
    "& = & \\int \\underbrace{\\left( \\int \\left(\\sum_{k=2}^t s_k(x_{k-1}, x_{k})\\right) p(x_{1:t-1}|y_{1:t-1},x_t) dx_{1:t-1} \\right)}_{=V_t(x_t)} p(x_{t}|y_{1:t})  dx_t\n",
    "\\end{eqnarray}\n",
    "\n",
    "Due to additivity, we can decompose further\n",
    "\\begin{eqnarray}\n",
    "V_t(x_t) & = & \\int \\left( s_t(x_{t-1}, x_{t}) + \\sum_{k=2}^{t-1} s_k(x_{k-1}, x_{k})  \\right) p(x_{1:t-1}|y_{1:t-1}, x_t) dx_{1:t-1} \\\\\n",
    "& = & \\int \\int \\left( s_t(x_{t-1}, x_{t}) + \\sum_{k=2}^{t-1} s_k(x_{k-1}, x_{k})  \\right) p(x_{1:t-2}|y_{1:t-2}, x_{t-1}) p(x_{t-1}|y_{1:t-1}, x_t) dx_{1:t-2} dx_{t-1} \\\\\n",
    "& = & \\int \\left( s_t(x_{t-1}, x_{t}) + \\int \\sum_{k=2}^{t-1} s_k(x_{k-1}, x_{k}) p(x_{1:t-2}|y_{1:t-2}, x_{t-1}) dx_{1:t-2}  \\right)  p(x_{t-1}|y_{1:t-1}, x_t)  dx_{t-1} \\\\\n",
    "& = & \\int \\left( s_t(x_{t-1}, x_{t}) + V_{t-1}(x_{t-1})  \\right)  p(x_{t-1}|y_{1:t-1}, x_t)  dx_{t-1}\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "V_1(x_1) & = & 0 \\\\\n",
    "V_2(x_2) & = & \\int  s_2(x_{1}, x_{2})   p(x_{1}|y_{1}, x_2)  dx_{1} \\\\\n",
    "V_3(x_3) & = & \\int \\left( s_3(x_{2}, x_{3}) + V_{2}(x_{2})  \\right)  p(x_{2}|y_{1:2}, x_3)  dx_{2}\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example \n",
    "Suppose only $y_{1:4}$ are observed. The above recursion, when applied to the sufficient statistics of an HMM has the following specific form. Recall that, $C_{\\pi}, C_A, C_B$ for stand for the sufficient statistics for the estimation of the prior, state transitions  and observations, respectively. Here, we will denote the expected sufficient statistics explicitely as $C_{A,t}$ where $t$ is the number of observations. \n",
    "\n",
    "The state transition statistics are\n",
    "\\begin{eqnarray}\n",
    "C_{A,4}(a,b) &=& \\sum_{x_4} \\sum_{x_3} \\sum_{x_2} \\sum_{x_1} \\left( {\\ind{a = x_2}}\\ind{b = x_{1}} + {\\ind{a = x_3}}\\ind{b = x_2} + {\\ind{a = x_4}}\\ind{b = x_3} \\right) p(x_{1:4}|y_{1,4})\\\\\n",
    "\\end{eqnarray}\n",
    "By introducing the forward decomposition\n",
    "\\begin{eqnarray}\n",
    "C_{A,4}(a,b) &=& \\sum_{x_4} \\sum_{x_3} \\sum_{x_2} \\left(\\sum_{x_1} {\\ind{a = x_2}}\\ind{b = x_{1}} p(x_1|y_1, x_2) + {\\ind{a = x_3}}\\ind{b = x_2} + {\\ind{a = x_4}}\\ind{b = x_3} \\right) \\\\\n",
    "& & p(x_2|y_{1,2}, x_3) p(x_3|y_{1,3}, x_4) p(x_4|y_{1,4})\\\\\n",
    "&=& \\sum_{x_4}\\sum_{x_3} \\sum_{x_2} \\left( \\underbrace{{\\ind{a = x_2}} p(x_1=b|y_1, x_2)}_{V_{A,2}(x_2)} + {\\ind{a = x_3}}\\ind{b = x_2} + {\\ind{a = x_4}}\\ind{b = x_3} \\right) \\\\\n",
    "& & p(x_2|y_{1,2}, x_3) p(x_3|y_{1,3}, x_4) p(x_4|y_{1,4}) \\\\\n",
    "&=&  \\sum_{x_4}\\sum_{x_3} \\left( \\underbrace{p(x_1=b|y_1, x_2=a) p(x_2=a|y_{1,2}, x_3) + {\\ind{a = x_3}} p(x_2=b|y_{1,2}, x_3)}_{V_{A,3}(x_3)} + {\\ind{a = x_4}}\\ind{b = x_3} \\right) \\\\\n",
    "& & p(x_3|y_{1,3}, x_4) p(x_4|y_{1,4}) \\\\\n",
    "&=&  \\sum_{x_4} \\left(p(x_1=b|y_1, x_2=a)\\sum_{x_3} p(x_2=a|y_{1,2}, x_3) p(x_3|y_{1,3}, x_4) + p(x_2=b|y_{1,2}, x_3=a) p(x_3=a|y_{1,3}, x_4) \\\\\n",
    "+ {\\ind{a = x_4}} p(x_3=b |y_{1,3}, x_4) \\right)  p(x_4|y_{1,4}) \\\\\n",
    "&=& p(x_1=b|y_1, x_2=a)\\sum_{x_3} p(x_2=a|y_{1,2}, x_3) \\sum_{x_4} p(x_3|y_{1,3}, x_4) p(x_4|y_{1,4}) \\\\\n",
    "& & + p(x_2=b|y_{1,2}, x_3=a) \\sum_{x_4} p(x_3=a|y_{1,3}, x_4)p(x_4|y_{1,4}) \\\\\n",
    "& & + p(x_3=b |y_{1,3}, x_4=a) p(x_4=a|y_{1,4})  \n",
    "\\end{eqnarray}\n",
    "\n",
    "One can verify, that the last line is indeed equal to the required sufficient statistics given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "C_{A,T}(a,b) & = &  \\sum_{x_{1:T}} \\sum_{t=2}^T \\ind{a = x_t}\\ind{b = x_{t-1}} \\left( \\prod_{t=2:T} p(x_{t-1}|y_{1:t-1},x_{t}) \\right) p(x_T|y_{1:T}) \\\\\n",
    "& = & \\sum_{x_{2:T}} \\left(\\sum_{x_{1}} \\ind{a = x_2}\\ind{b = x_{1}} p(x_{1}|y_{1},x_{2}) + \\sum_{t=3}^T \\ind{a = x_t}\\ind{b = x_{t-1}}  \\right) \\left( \\prod_{t=3:T} p(x_{t-1}|y_{1:t-1},x_{t}) \\right) p(x_T|y_{1:T}) \\\\\n",
    "V_{A,2}(a, b, x_2) & = & \\ind{a = x_2} p(x_{1} = b |y_{1},x_{2}) \\\\\n",
    "C_{A,T}(a,b) & = & \\sum_{x_{3:T}} \\left( \\sum_{x_2} V_2(a, b, x_2) p(x_{2}|y_{1:2},x_{3}) + \\sum_{x_2} \\ind{a = x_3}\\ind{b = x_{2}} p(x_{2}|y_{1:2},x_{3})  + \\sum_{t=4}^T \\ind{a = x_t}\\ind{b = x_{t-1}}  \\right) \\left( \\prod_{t=4:T} p(x_{t-1}|y_{1:t-1},x_{t}) \\right) p(x_T|y_{1:T}) \\\\\n",
    "V_{A,3}(a, b, x_3) & = & \\sum_{x_2} V_2(a, b, x_2) p(x_{2}|y_{1:2},x_{3}) + \\sum_{x_2} \\ind{a = x_3}\\ind{b = x_{2}} p(x_{2}|y_{1:2},x_{3}) \\\\\n",
    "& = & \\sum_{x_2} V_2(a, b, x_2) p(x_{2}|y_{1:2},x_{3}) + \\ind{a = x_3} p(x_{2}=b|y_{1:2},x_{3})\n",
    "\\end{eqnarray}\n",
    "\n",
    "For $t$, the update rule is \n",
    "\n",
    "\\begin{eqnarray}\n",
    "V_{A,t}(a, b, x_t) & = & \\sum_{x_{t-1}} V_{A,t-1}(a, b, x_{t-1}) p(x_{t-1}|y_{1:{t-1}},x_{t}) + \\sum_{x_{t-1}} \\ind{a = x_t}\\ind{b = x_{t-1}} p(x_{t-1}|y_{1:t-1},x_{t}) \\\\\n",
    "& = & \\sum_{x_{t-1}} V_{A,t-1}(a, b, x_{t-1}) p(x_{t-1}|y_{1:{t-1}},x_{t}) + \\ind{a = x_t} p(x_{t-1}=b|y_{1:t-1},x_{t})\n",
    "\\end{eqnarray}\n",
    "\n",
    "The advantage of this algorithm is that it is entirely forward and has attractive space properties, requiring only $S^3 + 2S$ space. The other statistics are derived below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "C_{B,T}(a,b) & = &  \\sum_{x_{1:T}} \\sum_{t=1}^T \\ind{a = y_t}\\ind{b = x_{t}} \\left( \\prod_{t=2:T} p(x_{t-1}|y_{1:t-1},x_{t}) \\right) p(x_T|y_{1:T}) \\\\\n",
    "& = &  \\sum_{x_{2:T}} \\left(\\ind{a = y_1} p(x_{1}=b|y_{1},x_{2}) + \\sum_{t=2}^T \\ind{a = y_t}\\ind{b = x_{t}} \\right) \\left( \\prod_{t=3:T} p(x_{t-1}|y_{1:t-1},x_{t}) \\right)  p(x_T|y_{1:T}) \\\\\n",
    "V_{B,2}(a, b, x_2)  & = & \\ind{a = y_1} p(x_{1}=b|y_{1},x_{2}) \\\\\n",
    "C_{B,T}(a,b) & = &  \\sum_{x_{3:T}} \\left(\\sum_{x_2} V_{B,2}(a, b, x_2) p(x_{2}|y_{1:2},x_{3}) + \\ind{a = y_2} p(x_{2}=b|y_{1:2},x_{3}) + \\sum_{t=3}^T \\ind{a = y_t}\\ind{b = x_{t}} \\right) \\left( \\prod_{t=4:T} p(x_{t-1}|y_{1:t-1},x_{t}) \\right)  p(x_T|y_{1:T}) \\\\\n",
    "V_{B,3}(a, b, x_3)  & = & \\sum_{x_2} V_{B,2}(a, b, x_2) p(x_{2}|y_{1:2},x_{3}) + \\ind{a = y_2} p(x_{2}=b|y_{1:2},x_{3})\n",
    "\\end{eqnarray}\n",
    "\n",
    "For $t$, the update rule is \n",
    "\n",
    "\\begin{eqnarray}\n",
    "V_{B,t}(a, b, x_t) & = & \\sum_{x_{t-1}} V_{B,t-1}(a, b, x_{t-1}) p(x_{t-1}|y_{1:{t-1}},x_{t}) + \\ind{a = y_t} p(x_{t-1}=b|y_{1:t-1},x_{t})\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "C_{\\pi,T}(a) & = &  \\sum_{x_{1:T}} \\ind{a = x_{1}} \\left( \\prod_{t=2:T} p(x_{t-1}|y_{1:t-1},x_{t}) \\right) p(x_T|y_{1:T}) \\\\\n",
    "& = &  \\sum_{x_{2:T}} p(x_{1}=a|y_{1},x_{2}) \\left( \\prod_{t=3:T} p(x_{t-1}|y_{1:t-1},x_{t}) \\right)  p(x_T|y_{1:T}) \\\\\n",
    "V_{\\pi,2}(a, x_2)  & = & p(x_{1}=a|y_{1},x_{2}) \\\\\n",
    "C_{\\pi,T}(a) & = &  \\sum_{x_{3:T}} \\sum_{x_2} V_{1,2}(a, x_2) p(x_{2}|y_{1:2},x_{3})  \\left( \\prod_{t=4:T} p(x_{t-1}|y_{1:t-1},x_{t}) \\right)  p(x_T|y_{1:T}) \\\\\n",
    "V_{\\pi,3}(a, x_3)  & = & \\sum_{x_2} V_{\\pi,2}(a, x_2) p(x_{2}|y_{1:2},x_{3})\n",
    "\\end{eqnarray}\n",
    "\n",
    "For $t$, the update equation is \n",
    "\\begin{eqnarray}\n",
    "V_{\\pi,t}(a, x_t)  & = & \\sum_{x_{t-1}} V_{\\pi,t-1}(a, x_{t-1}) p(x_{t-1}|y_{1:{t-1}},x_{t})\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " An implementation is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with the Forward Smoother\n",
      "[[ 0.02937541]\n",
      " [ 0.01479263]\n",
      " [ 0.95583195]]\n",
      "1.0\n",
      "[[ 0.10147144  2.25321693  1.3688555 ]\n",
      " [ 3.29750268  2.2347144   1.2879098 ]\n",
      " [ 0.01597626  2.12380948  0.3165435 ]]\n",
      "13.0\n",
      "[[ 0.77975177  1.80508346  0.41516477]\n",
      " [ 1.22828121  1.31928887  1.45242992]\n",
      " [ 0.10490948  2.66139344  0.23369708]\n",
      " [ 1.30200792  0.82597504  0.87201704]\n",
      " [ 0.33796891  0.2231787   0.4388524 ]]\n",
      "14.0\n",
      "Results with the Correction Smoother\n",
      "[ 0.02937541  0.01479263  0.95583195]\n",
      "1.0\n",
      "[[ 0.10147144  2.25321693  1.3688555 ]\n",
      " [ 3.29750268  2.2347144   1.2879098 ]\n",
      " [ 0.01597626  2.12380948  0.3165435 ]]\n",
      "13.0\n",
      "[[ 0.77975177  1.80508346  0.41516477]\n",
      " [ 1.22828121  1.31928887  1.45242992]\n",
      " [ 0.10490948  2.66139344  0.23369708]\n",
      " [ 1.30200792  0.82597504  0.87201704]\n",
      " [ 0.33796891  0.2231787   0.4388524 ]]\n",
      "14.0\n"
     ]
    }
   ],
   "source": [
    "S = 3\n",
    "R = 5\n",
    "A = np.random.dirichlet(0.7*np.ones(S),S).T\n",
    "B = np.random.dirichlet(0.7*np.ones(R),S).T\n",
    "p = np.random.dirichlet(0.7*np.ones(S)).T\n",
    "\n",
    "logA = np.log(A)\n",
    "logB = np.log(B)\n",
    "\n",
    "hm = HMM(p, A, B)\n",
    "\n",
    "y = np.array([1, 1, 1, 3, 2, 0, 3, 2, 1, 0, 0, 3, 2, 4])\n",
    "T = y.shape[0]\n",
    "\n",
    "# Forward only estimation of sufficient statistics\n",
    "V_pi  = np.eye((S))\n",
    "V_A  = np.zeros((S,S,S))\n",
    "V_B  = np.zeros((R,S,S))\n",
    "I_S1S = np.eye(S).reshape((S,1,S))\n",
    "I_RR = np.eye(R)\n",
    "\n",
    "for k in range(T):\n",
    "    if k==0:\n",
    "        log_alpha_pred = np.log(p)\n",
    "    else:\n",
    "        log_alpha_pred = predict(A, log_alpha)\n",
    "    \n",
    "    if k>0:\n",
    "        # Calculate p(x_{k-1}|y_{1:k-1}, x_k) \n",
    "        lp = np.log(normalize_exp(log_alpha)).reshape(S,1) + logA.T    \n",
    "        P = normalize_exp(lp, axis=0)\n",
    "        \n",
    "        # Update\n",
    "        V_pi = np.dot(V_pi, P)             \n",
    "        V_A = np.dot(V_A, P) + I_S1S*P.reshape((1,S,S))    \n",
    "        V_B = np.dot(V_B, P) + I_RR[:,y[k-1]].reshape((R,1,1))*P.reshape((1,S,S))    \n",
    "        \n",
    "    log_alpha = update(y[k], logB, log_alpha_pred)    \n",
    "    p_xT = normalize_exp(log_alpha)    \n",
    "    \n",
    "C1 = np.dot(V_pi, p_xT.reshape(S,1))\n",
    "C2 = np.dot(V_A, p_xT.reshape(1,S,1)).reshape((S,S))\n",
    "C3 = np.dot(V_B, p_xT.reshape(1,S,1)).reshape((R,S))\n",
    "C3[y[-1],:] +=  p_xT\n",
    "    \n",
    "print(\"Results with the Forward Smoother\")\n",
    "print(C1)\n",
    "print(np.sum(C1))\n",
    "\n",
    "print(C2)\n",
    "print(np.sum(C2))\n",
    "\n",
    "print(C3)\n",
    "print(np.sum(C3))\n",
    "\n",
    "print(\"Results with the Correction Smoother\")\n",
    "lg, C1_corr, C2_corr, C3_corr = hm.correction_smoother(y)\n",
    "\n",
    "print(C1_corr)\n",
    "print(np.sum(C1_corr))\n",
    "\n",
    "print(C2_corr)\n",
    "print(np.sum(C2_corr))\n",
    "\n",
    "print(C3_corr)\n",
    "print(np.sum(C3_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"stdin_port\": 51865, \n",
      "  \"ip\": \"127.0.0.1\", \n",
      "  \"control_port\": 51866, \n",
      "  \"hb_port\": 51867, \n",
      "  \"signature_scheme\": \"hmac-sha256\", \n",
      "  \"key\": \"859ed0bd-25dd-44c3-8963-504c654b53f5\", \n",
      "  \"kernel_name\": \"\", \n",
      "  \"shell_port\": 51863, \n",
      "  \"transport\": \"tcp\", \n",
      "  \"iopub_port\": 51864\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-41ae066c-2372-47bc-b4f9-9e82ca8021b6.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "%connect_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
